# Runbook

Dieses Runbook bietet Anweisungen zum lokalen Ausf√ºhren der agentic ELT-Pipeline, zur Validierung von Ergebnissen und zur Fehlerbehebung h√§ufiger Probleme. Alle Befehle sind relativ zum Projektroot.

## Voraussetzungen

- **Python 3.8+** (getestet mit Python 3.12)
- **OpenAI API Key** (f√ºr LLM-Agents)
- **Git** f√ºr Versionskontrolle

Abh√§ngigkeiten installieren:

```bash
pip install -r requirements.txt
```

## Umgebungssetup

1. **Virtuelle Umgebung erstellen:**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

2. **Umgebungsvariablen einrichten:**
```bash
# Beispiel-Umgebungsdatei kopieren
cp configs\.env.example .env
# .env bearbeiten und OpenAI API Key hinzuf√ºgen
# OPENAI_API_KEY=your_api_key_here
```

## Pipeline ausf√ºhren

Um die komplette agentic ELT-Pipeline auszuf√ºhren:

```bash
python .\src\runs\start_run.py
```

Die Pipeline wird automatisch:
1. **ü•â Bronze Layer** - Rohe CSV-Daten aufnehmen
2. **ü•à Silver Layer** - LLM-Agents bereinigen und standardisieren Daten
3. **ü•á Gold Layer** - LLM-Agents erstellen Business Data Marts
4. **üìä Business Insights** - Executive Reports und Visualisierungen generieren

## Pipeline-Ausgabestruktur

Alle Ausgaben sind nach Run-ID organisiert:

```
artifacts/
‚îú‚îÄ‚îÄ bronze/YYYYMMDD_HHMMSS_#hash/     # Rohdaten-Snapshots
‚îú‚îÄ‚îÄ silver/YYYYMMDD_HHMMSS_#hash/      # Bereinigte Daten (neuer Zeitstempel, gleicher Suffix)
‚îú‚îÄ‚îÄ gold/marts/YYYYMMDD_HHMMSS_#hash/  # Business Marts (Bronze run_id f√ºr Konsistenz)
‚îú‚îÄ‚îÄ orchestrator/YYYYMMDD_HHMMSS_#hash/# Ausf√ºhrungslogs
‚îî‚îÄ‚îÄ reports/YYYYMMDD_HHMMSS_#hash/     # Zusammenfassungsberichte
```

## Run-ID Logik

- **Bronze**: Generiert initiale run_id (z.B. `20260125_204110_#527f1cea`)
- **Silver**: Erstellt neue run_id mit frischem Zeitstempel aber gleichem Suffix (z.B. `20260125_204143_#527f1cea`)
- **Gold**: Verwendet Bronze run_id f√ºr Mart-Konsistenz
- **Reports**: Verwenden Orchestrator run_id

## Ergebnisse validieren

Das Repository enth√§lt eine umfassende Test-Suite:

```bash
pytest -q
```

Tests umfassen:
- Unit-Tests f√ºr Transformationen
- Vertragstests f√ºr Ausgabe-Artefakte
- Integrationstests f√ºr End-to-End-Pipeline
- Qualit√§tstests f√ºr generierten Code

## Fehlerbehebung

### H√§ufige Probleme

**Fehlender OpenAI API Key:**
```
RuntimeError: Missing OPEN_AI_KEY or OPENAI_API_KEY in .env
```
L√∂sung: OpenAI API Key zur `.env` Datei hinzuf√ºgen

**Fehlende Rohdaten:**
```
FileNotFoundError: Missing required raw source directories
```
L√∂sung: Sicherstellen, dass `raw/source_crm` und `raw/source_erp` CSV-Dateien enthalten

**Berechtigungsfehler:**
```
PermissionError: [Errno 13] Permission denied
```
L√∂sung: Schreibberechtigungen f√ºr `artifacts/` Verzeichnis pr√ºfen

**Agent-Fehler:**
- `artifacts/orchestrator/*/logs/` f√ºr detaillierte Fehlerlogs pr√ºfen
- OpenAI API Key hat ausreichend Credits verifizieren
- LLM-Agent-Kontext in `tmp/draft_reports/` √ºberpr√ºfen

### Pipeline-Optionen

**LLM-Agents √ºberspringen (f√ºr Tests):**
```bash
python .\src\runs\start_run.py --skip-llm
```

**Benutzerdefinierte Run-ID:**
```bash
set ORCHESTRATOR_RUN_ID=custom_run_id
python .\src\runs\start_run.py
```

### Inkrementelle Verarbeitung

Die Pipeline erkennt automatisch unver√§nderte Rohdaten und √ºberspringt die Verarbeitung, wenn keine neuen Daten verf√ºgbar sind, wodurch Zeit und Ressourcen gespart werden.

### Hilfe erhalten

- Ausf√ºhrungslogs in `artifacts/orchestrator/*/logs/` pr√ºfen
- Agent-Kontext in `tmp/draft_reports/` √ºberpr√ºfen
- Debug-Logging durch Setzen von `LOG_LEVEL=DEBUG` in `.env` aktivieren
- Bestehende [Issues](https://github.com/YOUR_USERNAME/agentic-elt-data-warehouse/issues) pr√ºfen