{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bronze-zu-Silver Agent Flow\n",
    "\n",
    "## Ãœberblick\n",
    "Dieses Notebook demonstriert den **Datenbereinigungsprozess** der Agentic ELT Pipeline.\n",
    "Der Silver Layer transformiert rohe Bronze-Daten in bereinigte, standardisierte Tabellen.\n",
    "\n",
    "### Agent-Workflow:\n",
    "1. **Silver Draft Agent** â†’ Analysiert DatenqualitÃ¤t und plant Transformationen\n",
    "2. **Silver Builder Agent** â†’ Generiert ausfÃ¼hrbaren Python-Code\n",
    "3. **Silver Runner** â†’ FÃ¼hrt Bereinigung aus und erstellt Silver-Tabellen\n",
    "\n",
    "### Was Sie lernen:\n",
    "- Wie LLM-Agents DatenqualitÃ¤tsprobleme automatisch erkennen\n",
    "- Welche Transformationen fÃ¼r Datenbereinigung angewendet werden\n",
    "- Wie Agents Code fÃ¼r ETL-Prozesse generieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Setup und Konfiguration\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Laden der benÃ¶tigten Python-Bibliotheken\n",
    "- Definition der Pfade zu Bronze- und Silver-Artefakten\n",
    "- ÃœberprÃ¼fung der DatenverfÃ¼gbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ÃœberprÃ¼fe Datenverzeichnisse:\n",
      "Bronze Directory: ..\\artifacts\\bronze\\20260124_231016_#6470e523 (âœ… vorhanden)\n",
      "Silver Directory: ..\\artifacts\\silver\\20260124_231016_#6470e523 (âœ… vorhanden)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Setzen Sie hier Ihre Run-ID\n",
    "run_id = \"20260124_231016_#6470e523\"\n",
    "\n",
    "# Pfade definieren\n",
    "bronze_dir = Path(f\"../artifacts/bronze/{run_id}\")\n",
    "silver_dir = Path(f\"../artifacts/silver/{run_id}\")\n",
    "\n",
    "print(f\"ğŸ” ÃœberprÃ¼fe Datenverzeichnisse:\")\n",
    "print(f\"Bronze Directory: {bronze_dir} ({'âœ… vorhanden' if bronze_dir.exists() else 'âŒ fehlt'})\")\n",
    "print(f\"Silver Directory: {silver_dir} ({'âœ… vorhanden' if silver_dir.exists() else 'âŒ fehlt'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥‰ Bronze Layer Inspektion\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Analyse der rohen Eingangsdaten aus dem Bronze Layer\n",
    "- ÃœberprÃ¼fung der Metadaten und Datenstrukturen\n",
    "- Identifikation der verfÃ¼gbaren Tabellen und deren Eigenschaften\n",
    "\n",
    "**Warum wichtig:**\n",
    "Der Silver Draft Agent benÃ¶tigt diese Informationen, um DatenqualitÃ¤tsprobleme zu erkennen und Transformationsstrategien zu entwickeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Bronze Layer Metadata:\n",
      "Run ID: 20260124_231016_#6470e523\n",
      "Layer: bronze\n",
      "\n",
      "ğŸ“ˆ Ingestion Zusammenfassung:\n",
      "  Dateien gesamt: 9\n",
      "  Dateien erfolgreich: 9\n",
      "  Dateien fehlgeschlagen: 0\n"
     ]
    }
   ],
   "source": [
    "# Bronze Metadata analysieren (robust + validiert)\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "def _load_yaml(path: Path) -> dict:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Metadata nicht gefunden: {path.resolve()}\")\n",
    "    data = yaml.safe_load(path.read_text(encoding=\"utf-8\")) or {}\n",
    "    if not isinstance(data, dict):\n",
    "        raise TypeError(f\"Unerwartetes YAML-Format (kein Mapping) in {path.resolve()}: {type(data)}\")\n",
    "    return data\n",
    "\n",
    "def _require(meta: dict, *keys: str, path: Path = None):\n",
    "    cur = meta\n",
    "    for k in keys:\n",
    "        if not isinstance(cur, dict) or k not in cur:\n",
    "            available = list(cur.keys()) if isinstance(cur, dict) else None\n",
    "            where = f\" in {path.resolve()}\" if path else \"\"\n",
    "            raise KeyError(\n",
    "                f\"Fehlender Key: {'/'.join(keys)}{where}. \"\n",
    "                f\"VerfÃ¼gbare Keys auf dieser Ebene: {available}\"\n",
    "            )\n",
    "        cur = cur[k]\n",
    "    return cur\n",
    "\n",
    "bronze_metadata_path = bronze_dir / \"data\" / \"metadata.yaml\"\n",
    "bronze_metadata = None\n",
    "\n",
    "try:\n",
    "    bronze_metadata = _load_yaml(bronze_metadata_path)\n",
    "\n",
    "    # Pflichtfelder (frÃ¼h & laut scheitern, falls Schema nicht passt)\n",
    "    run_id_val = _require(bronze_metadata, \"run\", \"run_id\", path=bronze_metadata_path)\n",
    "    layer_val  = _require(bronze_metadata, \"run\", \"layer\",  path=bronze_metadata_path)\n",
    "\n",
    "    print(\"ğŸ“Š Bronze Layer Metadata:\")\n",
    "    print(f\"Run ID: {run_id_val}\")\n",
    "    print(f\"Layer: {layer_val}\")\n",
    "\n",
    "    # Optionale Felder\n",
    "    summary = bronze_metadata.get(\"summary\", {}) or {}\n",
    "    print(f\"\\nğŸ“ˆ Ingestion Zusammenfassung:\")\n",
    "    print(f\"  Dateien gesamt: {summary.get('files_total')}\")\n",
    "    print(f\"  Dateien erfolgreich: {summary.get('files_success')}\")\n",
    "    print(f\"  Dateien fehlgeschlagen: {summary.get('files_failed')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"âŒ Fehler beim Laden/Validieren der Bronze-Metadata:\")\n",
    "    print(f\"  {e}\")\n",
    "    print(\"\\nğŸ” Debug:\")\n",
    "    print(f\"  Pfad: {bronze_metadata_path}\")\n",
    "    print(f\"  Absolut: {bronze_metadata_path.resolve()}\")\n",
    "    print(f\"  Existiert: {bronze_metadata_path.exists()}\")\n",
    "\n",
    "    if isinstance(bronze_metadata, dict):\n",
    "        print(f\"  Top-Level Keys: {list(bronze_metadata.keys())}\")\n",
    "        run_block = bronze_metadata.get(\"run\")\n",
    "        if isinstance(run_block, dict):\n",
    "            print(f\"  run Keys: {list(run_block.keys())}\")\n",
    "        else:\n",
    "            print(f\"  run Typ: {type(run_block)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‚ï¸ Bronze Tabellen (9 gefunden):\n",
      "\n",
      "ğŸ“‹ CST_AZ12.csv:\n",
      "  Dimensionen: 18484 Zeilen Ã— 3 Spalten\n",
      "  Spalten: ['CID', 'BDATE', 'GEN']\n",
      "  QualitÃ¤t: 1472 NULL-Werte, 0 Duplikate\n",
      "\n",
      "ğŸ“‹ cst_info.csv:\n",
      "  Dimensionen: 18494 Zeilen Ã— 7 Spalten\n",
      "  Spalten: ['cst_id', 'cst_key', 'cst_firstname', 'cst_lastname', 'cst_marital_status', 'cst_gndr', 'cst_create_date']\n",
      "  QualitÃ¤t: 4608 NULL-Werte, 0 Duplikate\n",
      "\n",
      "ğŸ“‹ customer_info.csv:\n",
      "  Dimensionen: 5 Zeilen Ã— 5 Spalten\n",
      "  Spalten: ['customer_id', 'firstname', 'lastname', 'gender', 'date_of_birth']\n",
      "  QualitÃ¤t: 0 NULL-Werte, 0 Duplikate\n",
      "\n",
      "ğŸ“‹ LOC_A101.csv:\n",
      "  Dimensionen: 18484 Zeilen Ã— 2 Spalten\n",
      "  Spalten: ['CID', 'CNTRY']\n",
      "  QualitÃ¤t: 332 NULL-Werte, 0 Duplikate\n",
      "\n",
      "ğŸ“‹ prd_info.csv:\n",
      "  Dimensionen: 397 Zeilen Ã— 7 Spalten\n",
      "  Spalten: ['prd_id', 'prd_key', 'prd_nm', 'prd_cost', 'prd_line', 'prd_start_dt', 'prd_end_dt']\n",
      "  QualitÃ¤t: 216 NULL-Werte, 0 Duplikate\n",
      "\n",
      "ğŸ“‹ product_info.csv:\n",
      "  Dimensionen: 4 Zeilen Ã— 4 Spalten\n",
      "  Spalten: ['product_id', 'product_name', 'category', 'price']\n",
      "  QualitÃ¤t: 0 NULL-Werte, 0 Duplikate\n",
      "\n",
      "ğŸ“‹ PX_CAT_G1V2.csv:\n",
      "  Dimensionen: 37 Zeilen Ã— 4 Spalten\n",
      "  Spalten: ['ID', 'CAT', 'SUBCAT', 'MAINTENANCE']\n",
      "  QualitÃ¤t: 0 NULL-Werte, 0 Duplikate\n",
      "\n",
      "ğŸ“‹ sales_details.csv:\n",
      "  Dimensionen: 60398 Zeilen Ã— 9 Spalten\n",
      "  Spalten: ['sls_ord_num', 'sls_prd_key', 'sls_cust_id', 'sls_order_dt', 'sls_ship_dt', 'sls_due_dt', 'sls_sales', 'sls_quantity', 'sls_price']\n",
      "  QualitÃ¤t: 15 NULL-Werte, 0 Duplikate\n",
      "\n",
      "ğŸ“‹ sales_transactions.csv:\n",
      "  Dimensionen: 8 Zeilen Ã— 6 Spalten\n",
      "  Spalten: ['transaction_id', 'customer_id', 'product_id', 'quantity', 'unit_price', 'transaction_date']\n",
      "  QualitÃ¤t: 0 NULL-Werte, 0 Duplikate\n"
     ]
    }
   ],
   "source": [
    "# Bronze Tabellen inspizieren\n",
    "bronze_data_dir = bronze_dir / \"data\"\n",
    "csv_files = list(bronze_data_dir.glob(\"*.csv\"))\n",
    "\n",
    "print(f\"ğŸ—‚ï¸ Bronze Tabellen ({len(csv_files)} gefunden):\")\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"\\nğŸ“‹ {csv_file.name}:\")\n",
    "    print(f\"  Dimensionen: {df.shape[0]} Zeilen Ã— {df.shape[1]} Spalten\")\n",
    "    print(f\"  Spalten: {list(df.columns)}\")\n",
    "\n",
    "    # Erste DatenqualitÃ¤tsindikatoren\n",
    "    null_count = df.isnull().sum().sum()\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"  QualitÃ¤t: {null_count} NULL-Werte, {duplicate_count} Duplikate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Silver Draft Agent - Datenprofilierung\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Simulation der automatischen Datenprofilierung des Silver Draft Agents\n",
    "- Erkennung von DatenqualitÃ¤tsproblemen (NULL-Werte, Duplikate, Formatierungsfehler)\n",
    "- Generierung von Transformationsempfehlungen\n",
    "\n",
    "**Agent-Logik:**\n",
    "Der Silver Draft Agent analysiert jede Spalte auf:\n",
    "- Datentyp-Konsistenz\n",
    "- Whitespace-Probleme\n",
    "- Leere Strings vs. NULL-Werte\n",
    "- Duplikate auf Zeilenebene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Silver Draft Agent Analyse:\n",
      "\n",
      "ğŸ“Š Analyse: CST_AZ12.csv\n",
      "  QualitÃ¤tsprobleme: 2\n",
      "    - Whitespace in GEN\n",
      "    - 1472 NULLs in GEN\n",
      "  Transformationsplan:\n",
      "    - ğŸ§¹ Whitespace entfernen in 'GEN'\n",
      "    - âš ï¸ 1472 NULL-Werte behandeln in 'GEN'\n",
      "\n",
      "ğŸ“Š Analyse: cst_info.csv\n",
      "  QualitÃ¤tsprobleme: 8\n",
      "    - 4 NULLs in cst_id\n",
      "    - Whitespace in cst_firstname\n",
      "    - 8 NULLs in cst_firstname\n",
      "    - Whitespace in cst_lastname\n",
      "    - 7 NULLs in cst_lastname\n",
      "    - 7 NULLs in cst_marital_status\n",
      "    - 4578 NULLs in cst_gndr\n",
      "    - 4 NULLs in cst_create_date\n",
      "  Transformationsplan:\n",
      "    - âš ï¸ 4 NULL-Werte behandeln in 'cst_id'\n",
      "    - ğŸ§¹ Whitespace entfernen in 'cst_firstname'\n",
      "    - âš ï¸ 8 NULL-Werte behandeln in 'cst_firstname'\n",
      "    - ğŸ§¹ Whitespace entfernen in 'cst_lastname'\n",
      "    - âš ï¸ 7 NULL-Werte behandeln in 'cst_lastname'\n",
      "    - âš ï¸ 7 NULL-Werte behandeln in 'cst_marital_status'\n",
      "    - âš ï¸ 4578 NULL-Werte behandeln in 'cst_gndr'\n",
      "    - âš ï¸ 4 NULL-Werte behandeln in 'cst_create_date'\n",
      "\n",
      "ğŸ“Š Analyse: customer_info.csv\n",
      "  QualitÃ¤tsprobleme: 0\n",
      "  Transformationsplan:\n",
      "    - âœ… Keine Transformationen erforderlich\n",
      "\n",
      "ğŸ“Š Analyse: LOC_A101.csv\n",
      "  QualitÃ¤tsprobleme: 2\n",
      "    - Whitespace in CNTRY\n",
      "    - 332 NULLs in CNTRY\n",
      "  Transformationsplan:\n",
      "    - ğŸ§¹ Whitespace entfernen in 'CNTRY'\n",
      "    - âš ï¸ 332 NULL-Werte behandeln in 'CNTRY'\n",
      "\n",
      "ğŸ“Š Analyse: prd_info.csv\n",
      "  QualitÃ¤tsprobleme: 4\n",
      "    - 2 NULLs in prd_cost\n",
      "    - Whitespace in prd_line\n",
      "    - 17 NULLs in prd_line\n",
      "    - 197 NULLs in prd_end_dt\n",
      "  Transformationsplan:\n",
      "    - âš ï¸ 2 NULL-Werte behandeln in 'prd_cost'\n",
      "    - ğŸ§¹ Whitespace entfernen in 'prd_line'\n",
      "    - âš ï¸ 17 NULL-Werte behandeln in 'prd_line'\n",
      "    - âš ï¸ 197 NULL-Werte behandeln in 'prd_end_dt'\n",
      "\n",
      "ğŸ“Š Analyse: product_info.csv\n",
      "  QualitÃ¤tsprobleme: 0\n",
      "  Transformationsplan:\n",
      "    - âœ… Keine Transformationen erforderlich\n",
      "\n",
      "ğŸ“Š Analyse: PX_CAT_G1V2.csv\n",
      "  QualitÃ¤tsprobleme: 0\n",
      "  Transformationsplan:\n",
      "    - âœ… Keine Transformationen erforderlich\n",
      "\n",
      "ğŸ“Š Analyse: sales_details.csv\n",
      "  QualitÃ¤tsprobleme: 2\n",
      "    - 8 NULLs in sls_sales\n",
      "    - 7 NULLs in sls_price\n",
      "  Transformationsplan:\n",
      "    - âš ï¸ 8 NULL-Werte behandeln in 'sls_sales'\n",
      "    - âš ï¸ 7 NULL-Werte behandeln in 'sls_price'\n",
      "\n",
      "ğŸ“Š Analyse: sales_transactions.csv\n",
      "  QualitÃ¤tsprobleme: 0\n",
      "  Transformationsplan:\n",
      "    - âœ… Keine Transformationen erforderlich\n"
     ]
    }
   ],
   "source": [
    "def simulate_silver_draft_agent(df, filename):\n",
    "    \"\"\"Simuliert die Datenprofilierung des Silver Draft Agents\"\"\"\n",
    "    profile = {\n",
    "        \"table\": filename,\n",
    "        \"row_count\": len(df),\n",
    "        \"column_count\": len(df.columns),\n",
    "        \"columns\": list(df.columns)\n",
    "    }\n",
    "\n",
    "    # Agent-Analyse: Identifiziere Transformationsbedarfe\n",
    "    transforms = []\n",
    "    quality_issues = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        # PrÃ¼fe auf Whitespace-Probleme\n",
    "        if df[col].dtype == 'object':\n",
    "            if df[col].astype(str).str.strip().ne(df[col].astype(str)).any():\n",
    "                transforms.append(f\"ğŸ§¹ Whitespace entfernen in '{col}'\")\n",
    "                quality_issues.append(f\"Whitespace in {col}\")\n",
    "\n",
    "            # PrÃ¼fe auf leere Strings\n",
    "            if (df[col] == \"\").any():\n",
    "                transforms.append(f\"ğŸ”„ Leere Strings zu NULL konvertieren in '{col}'\")\n",
    "                quality_issues.append(f\"Leere Strings in {col}\")\n",
    "\n",
    "        # PrÃ¼fe auf NULL-Werte\n",
    "        null_count = df[col].isnull().sum()\n",
    "        if null_count > 0:\n",
    "            transforms.append(f\"âš ï¸ {null_count} NULL-Werte behandeln in '{col}'\")\n",
    "            quality_issues.append(f\"{null_count} NULLs in {col}\")\n",
    "\n",
    "    # PrÃ¼fe auf Duplikate\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    if duplicate_count > 0:\n",
    "        transforms.append(f\"ğŸ—‘ï¸ {duplicate_count} doppelte Zeilen entfernen\")\n",
    "        quality_issues.append(f\"{duplicate_count} doppelte Zeilen\")\n",
    "\n",
    "    profile[\"quality_issues\"] = quality_issues\n",
    "    profile[\"suggested_transforms\"] = transforms if transforms else [\"âœ… Keine Transformationen erforderlich\"]\n",
    "\n",
    "    return profile\n",
    "\n",
    "# FÃ¼hre Agent-Simulation fÃ¼r alle Tabellen aus\n",
    "print(\"ğŸ¤– Silver Draft Agent Analyse:\")\n",
    "table_profiles = {}\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    profile = simulate_silver_draft_agent(df, csv_file.name)\n",
    "    table_profiles[csv_file.name] = profile\n",
    "\n",
    "    print(f\"\\nğŸ“Š Analyse: {csv_file.name}\")\n",
    "    print(f\"  QualitÃ¤tsprobleme: {len(profile['quality_issues'])}\")\n",
    "    for issue in profile['quality_issues']:\n",
    "        print(f\"    - {issue}\")\n",
    "\n",
    "    print(f\"  Transformationsplan:\")\n",
    "    for transform in profile['suggested_transforms']:\n",
    "        print(f\"    - {transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ Silver Agent Context - LLM Output\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Inspektion des tatsÃ¤chlichen Outputs des Silver Draft Agents\n",
    "- ÃœberprÃ¼fung der vom LLM generierten Analyse und Empfehlungen\n",
    "- Vergleich zwischen simulierter und echter Agent-Analyse\n",
    "\n",
    "**Agent-Output:**\n",
    "Der Silver Draft Agent erstellt strukturierte JSON-Kontextdaten, die der Silver Builder Agent verwendet, um ausfÃ¼hrbaren Code zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Silver Draft Agent - LLM Output:\n",
      "Run ID: 20260124_231016_#6470e523\n",
      "Layer: silver\n",
      "Quell-Layer: bronze\n",
      "\n",
      "ğŸ“ˆ Agent Performance:\n",
      "  Zeilen verarbeitet: 116,311\n",
      "  Spalten verarbeitet: 47\n",
      "  Tabellen verarbeitet: 9\n",
      "  Tabellen fehlgeschlagen: 0\n",
      "\n",
      "ğŸ” Agent Schema-Analyse:\n",
      "  ğŸ“‹ CST_AZ12.csv: 18484 Zeilen, 3 Spalten\n",
      "  ğŸ“‹ cst_info.csv: 18494 Zeilen, 7 Spalten\n",
      "  ğŸ“‹ customer_info.csv: 5 Zeilen, 5 Spalten\n",
      "  ğŸ“‹ LOC_A101.csv: 18484 Zeilen, 2 Spalten\n",
      "  ğŸ“‹ prd_info.csv: 397 Zeilen, 7 Spalten\n",
      "  ğŸ“‹ product_info.csv: 4 Zeilen, 4 Spalten\n",
      "  ğŸ“‹ PX_CAT_G1V2.csv: 37 Zeilen, 4 Spalten\n",
      "  ğŸ“‹ sales_details.csv: 60398 Zeilen, 9 Spalten\n",
      "  ğŸ“‹ sales_transactions.csv: 8 Zeilen, 6 Spalten\n"
     ]
    }
   ],
   "source": [
    "# Silver Agent Context analysieren\n",
    "silver_context_path = silver_dir / \"reports\" / \"silver_run_agent_context.json\"\n",
    "if silver_context_path.exists():\n",
    "    with open(silver_context_path, 'r') as f:\n",
    "        silver_context = json.load(f)\n",
    "\n",
    "    print(\"ğŸ¤– Silver Draft Agent - LLM Output:\")\n",
    "    print(f\"Run ID: {silver_context.get('run_id')}\")\n",
    "    print(f\"Layer: {silver_context.get('layer')}\")\n",
    "    print(f\"Quell-Layer: {silver_context.get('source_layer')}\")\n",
    "\n",
    "    # Performance Metriken\n",
    "    perf = silver_context.get('performance_metrics', {})\n",
    "    print(f\"\\nğŸ“ˆ Agent Performance:\")\n",
    "    print(f\"  Zeilen verarbeitet: {perf.get('total_rows_processed', 0):,}\")\n",
    "    print(f\"  Spalten verarbeitet: {perf.get('total_columns_processed', 0):,}\")\n",
    "    print(f\"  Tabellen verarbeitet: {perf.get('tables_processed', 0)}\")\n",
    "    print(f\"  Tabellen fehlgeschlagen: {perf.get('tables_failed', 0)}\")\n",
    "\n",
    "    # Schema-Ãœbersicht vom Agent\n",
    "    if 'profile' in silver_context:\n",
    "        print(f\"\\nğŸ” Agent Schema-Analyse:\")\n",
    "        schema = silver_context['profile'].get('schema_overview', {})\n",
    "        for table in schema.get('tables', []):\n",
    "            print(f\"  ğŸ“‹ {table['table']}: {table['row_count']} Zeilen, {table['column_count']} Spalten\")\n",
    "else:\n",
    "    print(\"âŒ Silver Agent Context nicht gefunden - Agent wurde nicht ausgefÃ¼hrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Silver Human Report - LLM Insights\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Anzeige des menschenlesbaren Reports des Silver Draft Agents\n",
    "- ÃœberprÃ¼fung der LLM-generierten DatenqualitÃ¤tsanalyse\n",
    "- Einsicht in die Agent-Empfehlungen fÃ¼r Business-Stakeholder\n",
    "\n",
    "**Report-Inhalt:**\n",
    "Der Agent erstellt einen strukturierten Markdown-Report mit Executive Summary, DatenqualitÃ¤tsbewertung und Transformationsempfehlungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Silver Draft Agent - Human Report:\n",
      "============================================================\n",
      "# Silver Layer Run Report  \n",
      "**Run ID:** 20260124_231151_#6470e523  \n",
      "**Bronze Run ID:** 20260124_231016_#6470e523  \n",
      "**Run Timestamp:** 2026-01-24T23:10:17 UTC (Bronze layer)\n",
      "\n",
      "---\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "- All nine source tables from CRM and ERP systems were successfully ingested in the Bronze layer with no failures detected.\n",
      "- Silver layer transformations are planned to standardize missing values and data types without aggregations, ensuring clean, granular data ready for analytics.\n",
      "- The data schema is structurally sound with no duplicate rows, well-defined keys, and mostly non-null primary identifiers.\n",
      "- The Silver layer is well-prepared to support business problem exploration including customer retention, product and category performance, sales trends, and location-based analysis.\n",
      "- Opportunities exist to define KPIs for BI/dashboarding and to apply machine learning methods for customer and product segmentation leveraging the cleaned data.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Problem Definition & Objectives (Context for Downstream Analysis)\n",
      "\n",
      "Based on the available tables (customers, products, sales transactions, location, categories), typical business problems that could be explored include:  \n",
      "\n",
      "- **Declining repeat purchase rates or customer retention**  \n",
      "  Impact: Revenue loss  \n",
      "  Stakeholders: Marketing, Sales, Finance  \n",
      "  Decisions: Customer targeting, retention campaigns  \n",
      "  Assumption: Delivery time or product category affinity influences repeat purchases  \n",
      "\n",
      "- **High return or low sales conversion in specific product categories**  \n",
      "  Impact: Margin erosion and inventory inefficiency  \n",
      "  Stakeholders: Product management, Operations  \n",
      "\n",
      "... (390 weitere Zeilen)\n",
      "\n",
      "ğŸ“Š Report Statistiken:\n",
      "  GesamtlÃ¤nge: 16,834 Zeichen\n",
      "  Zeilen: 420\n",
      "  Abschnitte: 62 (geschÃ¤tzt)\n"
     ]
    }
   ],
   "source": [
    "# Silver Human Report inspizieren\n",
    "silver_report_path = silver_dir / \"reports\" / \"silver_run_human_report.md\"\n",
    "if silver_report_path.exists():\n",
    "    with open(silver_report_path, 'r', encoding='utf-8') as f:\n",
    "        silver_report = f.read()\n",
    "\n",
    "    print(\"ğŸ“„ Silver Draft Agent - Human Report:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Zeige ersten Teil des Reports\n",
    "    lines = silver_report.split('\\n')\n",
    "    for i, line in enumerate(lines[:30]):  # Erste 30 Zeilen\n",
    "        print(line)\n",
    "\n",
    "    if len(lines) > 30:\n",
    "        print(f\"\\n... ({len(lines)-30} weitere Zeilen)\")\n",
    "\n",
    "    print(f\"\\nğŸ“Š Report Statistiken:\")\n",
    "    print(f\"  GesamtlÃ¤nge: {len(silver_report):,} Zeichen\")\n",
    "    print(f\"  Zeilen: {len(lines)}\")\n",
    "    print(f\"  Abschnitte: {silver_report.count('#')} (geschÃ¤tzt)\")\n",
    "else:\n",
    "    print(\"âŒ Silver Human Report nicht gefunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥ˆ Silver Layer Ergebnisse\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Inspektion der transformierten Silver-Daten\n",
    "- Vergleich zwischen Bronze- und Silver-Versionen der Tabellen\n",
    "- ÃœberprÃ¼fung der DatenqualitÃ¤tsverbesserungen\n",
    "\n",
    "**Transformationsergebnisse:**\n",
    "Der Silver Runner hat die vom Silver Builder Agent generierten Transformationen ausgefÃ¼hrt und bereinigte Daten erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reports-Inhalt:\n",
      " - reports\\elt_report.html\n",
      " - reports\\silver_run_agent_context.json\n",
      " - reports\\silver_run_human_report.md\n",
      "\n",
      "Suche nach typischen Daten-Dateien unter silver_dir:\n",
      "Gefunden: 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(\"Reports-Inhalt:\")\n",
    "for p in sorted((silver_dir / \"reports\").rglob(\"*\")):\n",
    "    print(\" -\", p.relative_to(silver_dir))\n",
    "    \n",
    "print(\"\\nSuche nach typischen Daten-Dateien unter silver_dir:\")\n",
    "patterns = [\"*.csv\", \"*.parquet\", \"*.jsonl\", \"*.feather\", \"*.pkl\"]\n",
    "found = []\n",
    "for pat in patterns:\n",
    "    found += list(silver_dir.rglob(pat))\n",
    "\n",
    "# metadata.yaml/report-Dateien rausfiltern\n",
    "found = [p for p in found if p.name != \"metadata.yaml\" and \"reports\" not in p.parts]\n",
    "\n",
    "print(\"Gefunden:\", len(found))\n",
    "for p in found[:30]:\n",
    "    print(\" -\", p.relative_to(silver_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Silver Daten nicht gefunden - Transformation nicht ausgefÃ¼hrt\n"
     ]
    }
   ],
   "source": [
    "# Silver Transformationsergebnisse analysieren\n",
    "silver_data_dir = silver_dir / \"data\"\n",
    "if silver_data_dir.exists():\n",
    "    silver_csv_files = list(silver_data_dir.glob(\"*.csv\"))\n",
    "\n",
    "    print(f\"ğŸ¥ˆ Silver Layer Ergebnisse ({len(silver_csv_files)} Tabellen):\")\n",
    "\n",
    "    for csv_file in silver_csv_files:\n",
    "        df_silver = pd.read_csv(csv_file)\n",
    "        print(f\"\\nğŸ“Š {csv_file.name}:\")\n",
    "        print(f\"  Silver: {df_silver.shape[0]} Zeilen Ã— {df_silver.shape[1]} Spalten\")\n",
    "\n",
    "        # Vergleiche mit Bronze-Version\n",
    "        bronze_equivalent = bronze_data_dir / csv_file.name\n",
    "        if bronze_equivalent.exists():\n",
    "            df_bronze = pd.read_csv(bronze_equivalent)\n",
    "\n",
    "            # DatenqualitÃ¤tsverbesserungen\n",
    "            bronze_nulls = df_bronze.isnull().sum().sum()\n",
    "            silver_nulls = df_silver.isnull().sum().sum()\n",
    "            bronze_dupes = df_bronze.duplicated().sum()\n",
    "            silver_dupes = df_silver.duplicated().sum()\n",
    "\n",
    "            print(f\"  ğŸ“ˆ QualitÃ¤tsverbesserungen:\")\n",
    "            print(f\"    Zeilen: {df_bronze.shape[0]} â†’ {df_silver.shape[0]} ({df_silver.shape[0] - df_bronze.shape[0]:+d})\")\n",
    "            print(f\"    NULL-Werte: {bronze_nulls} â†’ {silver_nulls} ({silver_nulls - bronze_nulls:+d})\")\n",
    "            print(f\"    Duplikate: {bronze_dupes} â†’ {silver_dupes} ({silver_dupes - bronze_dupes:+d})\")\n",
    "\n",
    "            # Datentyp-Verbesserungen\n",
    "            print(f\"  ğŸ”„ Datentyp-Transformationen:\")\n",
    "            for col in df_silver.columns:\n",
    "                if col in df_bronze.columns:\n",
    "                    bronze_type = str(df_bronze[col].dtype)\n",
    "                    silver_type = str(df_silver[col].dtype)\n",
    "                    if bronze_type != silver_type:\n",
    "                        print(f\"    {col}: {bronze_type} â†’ {silver_type}\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ Keine Bronze-Vergleichsdaten gefunden\")\n",
    "else:\n",
    "    print(\"âŒ Silver Daten nicht gefunden - Transformation nicht ausgefÃ¼hrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š DatenqualitÃ¤ts-Dashboard\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Erstellung einer Ãœbersicht Ã¼ber die DatenqualitÃ¤tsverbesserungen\n",
    "- Quantifizierung der Agent-Performance\n",
    "- Bewertung der Transformationserfolge\n",
    "\n",
    "**QualitÃ¤tsmetriken:**\n",
    "Vergleich der DatenqualitÃ¤t vor und nach der Silver-Transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'silver_data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DatenqualitÃ¤ts-Dashboard erstellen\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msilver_data_dir\u001b[49m\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m bronze_data_dir\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“Š DATENQUALITÃ„TS-DASHBOARD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'silver_data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# DatenqualitÃ¤ts-Dashboard erstellen\n",
    "if silver_data_dir.exists() and bronze_data_dir.exists():\n",
    "    print(\"ğŸ“Š DATENQUALITÃ„TS-DASHBOARD\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    total_bronze_rows = 0\n",
    "    total_silver_rows = 0\n",
    "    total_bronze_nulls = 0\n",
    "    total_silver_nulls = 0\n",
    "    total_bronze_dupes = 0\n",
    "    total_silver_dupes = 0\n",
    "    tables_processed = 0\n",
    "\n",
    "    for csv_file in silver_csv_files:\n",
    "        bronze_file = bronze_data_dir / csv_file.name\n",
    "        if bronze_file.exists():\n",
    "            df_bronze = pd.read_csv(bronze_file)\n",
    "            df_silver = pd.read_csv(csv_file)\n",
    "\n",
    "            total_bronze_rows += len(df_bronze)\n",
    "            total_silver_rows += len(df_silver)\n",
    "            total_bronze_nulls += df_bronze.isnull().sum().sum()\n",
    "            total_silver_nulls += df_silver.isnull().sum().sum()\n",
    "            total_bronze_dupes += df_bronze.duplicated().sum()\n",
    "            total_silver_dupes += df_silver.duplicated().sum()\n",
    "            tables_processed += 1\n",
    "\n",
    "    print(f\"ğŸ“ˆ GESAMTSTATISTIKEN:\")\n",
    "    print(f\"  Tabellen verarbeitet: {tables_processed}\")\n",
    "    print(f\"  Zeilen: {total_bronze_rows:,} â†’ {total_silver_rows:,} ({total_silver_rows - total_bronze_rows:+,})\")\n",
    "    print(f\"  NULL-Werte: {total_bronze_nulls:,} â†’ {total_silver_nulls:,} ({total_silver_nulls - total_bronze_nulls:+,})\")\n",
    "    print(f\"  Duplikate: {total_bronze_dupes:,} â†’ {total_silver_dupes:,} ({total_silver_dupes - total_bronze_dupes:+,})\")\n",
    "\n",
    "    # QualitÃ¤tsscore berechnen\n",
    "    if total_bronze_rows > 0:\n",
    "        bronze_quality = (1 - (total_bronze_nulls + total_bronze_dupes) / (total_bronze_rows * 10)) * 100\n",
    "        silver_quality = (1 - (total_silver_nulls + total_silver_dupes) / (total_silver_rows * 10)) * 100\n",
    "        quality_improvement = silver_quality - bronze_quality\n",
    "\n",
    "        print(f\"\\nğŸ¯ QUALITÃ„TSSCORE:\")\n",
    "        print(f\"  Bronze Layer: {bronze_quality:.1f}%\")\n",
    "        print(f\"  Silver Layer: {silver_quality:.1f}%\")\n",
    "        print(f\"  Verbesserung: {quality_improvement:+.1f}%\")\n",
    "else:\n",
    "    print(\"âŒ Kann DatenqualitÃ¤ts-Dashboard nicht erstellen - Daten fehlen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Agent-Workflow Zusammenfassung\n",
    "\n",
    "**Was Sie gelernt haben:**\n",
    "Dieser Abschnitt fasst den gesamten Silver Agent Workflow zusammen und erklÃ¤rt die Rolle jedes Agents im Datenbereinigungsprozess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– SILVER AGENT WORKFLOW - ZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"1ï¸âƒ£ SILVER DRAFT AGENT (Analyse & Planung):\")\n",
    "print(\"   ğŸ” Liest Bronze-Metadaten und CSV-Dateien\")\n",
    "print(\"   ğŸ“Š FÃ¼hrt automatische Datenprofilierung durch\")\n",
    "print(\"   âš ï¸ Identifiziert DatenqualitÃ¤tsprobleme\")\n",
    "print(\"   ğŸ’¡ SchlÃ¤gt spezifische Transformationen vor\")\n",
    "print(\"   ğŸ“„ Erstellt silver_run_agent_context.json\")\n",
    "print(\"   ğŸ“ Erstellt silver_run_human_report.md\")\n",
    "print()\n",
    "print(\"2ï¸âƒ£ SILVER BUILDER AGENT (Code-Generierung):\")\n",
    "print(\"   ğŸ“– Liest Silver Draft Context\")\n",
    "print(\"   ğŸ› ï¸ Generiert ausfÃ¼hrbaren Python-Code\")\n",
    "print(\"   ğŸ”§ Implementiert vorgeschlagene Transformationen\")\n",
    "print(\"   ğŸ“œ Erstellt load_2_silver_layer_runner.py\")\n",
    "print()\n",
    "print(\"3ï¸âƒ£ SILVER RUNNER (AusfÃ¼hrung):\")\n",
    "print(\"   â–¶ï¸ FÃ¼hrt generierten Code aus\")\n",
    "print(\"   ğŸ”„ Transformiert Bronze â†’ Silver\")\n",
    "print(\"   ğŸ’¾ Erstellt bereinigte CSV-Dateien\")\n",
    "print(\"   ğŸ“‹ Generiert Metadaten und Reports\")\n",
    "print()\n",
    "print(\"âœ… ERGEBNIS: Bereinigte, standardisierte Silver-Layer Daten\")\n",
    "print(\"   - Konsistente Datentypen\")\n",
    "print(\"   - Entfernte Duplikate\")\n",
    "print(\"   - Standardisierte NULL-Werte\")\n",
    "print(\"   - Bereinigte Formatierung\")\n",
    "print(\"   - VollstÃ¤ndige Dokumentation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
