{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Insights Agent Flow\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the **business intelligence generation process** of the Agentic ELT Pipeline.\n",
    "The Business Insights Agent transforms Gold data marts into actionable business insights and reports.\n",
    "\n",
    "### Agent Workflow:\n",
    "1. **Data Analysis** â†’ Analyzes Gold data marts for business KPIs\n",
    "2. **Insight Generation** â†’ Creates data-driven business insights\n",
    "3. **Report Creation** â†’ Generates stakeholder-specific reports\n",
    "4. **Visualization** â†’ Creates charts and dashboards\n",
    "\n",
    "### What you'll learn:\n",
    "- How LLM agents analyze business data for insights\n",
    "- Which KPIs and metrics are automatically calculated\n",
    "- How agents create targeted reports for different business roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Setup and Configuration\n",
    "\n",
    "**What happens here:**\n",
    "- Load required Python libraries\n",
    "- Define paths to reports, Gold data marts, and orchestrator logs\n",
    "- Verify availability of business intelligence artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# Set your Orchestrator Run ID here\n",
    "orchestrator_run_id = \"20260124_231016_#6470e523\"\n",
    "\n",
    "# Define paths\n",
    "reports_dir = Path(f\"../artifacts/reports/{orchestrator_run_id}\")\n",
    "gold_dir = Path(f\"../artifacts/gold/marts/{orchestrator_run_id}\")\n",
    "orchestrator_dir = Path(f\"../artifacts/orchestrator/{orchestrator_run_id}\")\n",
    "\n",
    "print(f\"ğŸ” Checking business intelligence directories:\")\n",
    "print(f\"Reports Directory: {reports_dir} ({'âœ… exists' if reports_dir.exists() else 'âŒ missing'})\")\n",
    "print(f\"Gold Directory: {gold_dir} ({'âœ… exists' if gold_dir.exists() else 'âŒ missing'})\")\n",
    "print(f\"Orchestrator Directory: {orchestrator_dir} ({'âœ… exists' if orchestrator_dir.exists() else 'âŒ missing'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Pipeline Execution Analysis\n",
    "\n",
    "**What happens here:**\n",
    "- Analyze the complete pipeline execution summary\n",
    "- Review performance metrics and execution times\n",
    "- Understand data flow through Bronze â†’ Silver â†’ Gold layers\n",
    "\n",
    "**Why important:**\n",
    "The Business Insights Agent uses pipeline execution data to provide context about data freshness, processing success, and system performance in its reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pipeline execution summary\n",
    "summary_json_path = reports_dir / \"summary_report.json\"\n",
    "if summary_json_path.exists():\n",
    "    with open(summary_json_path, 'r') as f:\n",
    "        summary_report = json.load(f)\n",
    "    \n",
    "    print(\"ğŸ“Š PIPELINE EXECUTION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"\\nâ±ï¸ Execution Timeline:\")\n",
    "    print(f\"  Run ID: {summary_report.get('run_id')}\")\n",
    "    print(f\"  Started: {summary_report.get('started_utc')}\")\n",
    "    print(f\"  Ended: {summary_report.get('ended_utc')}\")\n",
    "    print(f\"  Duration: {summary_report.get('duration_s', 0):.2f} seconds\")\n",
    "    \n",
    "    # Step-by-step analysis\n",
    "    steps = summary_report.get('step_results', [])\n",
    "    print(f\"\\nğŸ”„ Pipeline Steps ({len(steps)} total):\")\n",
    "    \n",
    "    successful_steps = 0\n",
    "    failed_steps = 0\n",
    "    total_duration = 0\n",
    "    \n",
    "    for step in steps:\n",
    "        status = step.get('status', 'unknown')\n",
    "        duration = step.get('duration_s', 0)\n",
    "        total_duration += duration\n",
    "        \n",
    "        status_icon = \"âœ…\" if status == \"success\" else \"â­ï¸\" if status == \"skipped\" else \"âŒ\"\n",
    "        print(f\"  {status_icon} {step.get('name')}: {status} ({duration:.2f}s)\")\n",
    "        \n",
    "        if status == \"success\":\n",
    "            successful_steps += 1\n",
    "        elif status == \"failed\":\n",
    "            failed_steps += 1\n",
    "    \n",
    "    # Layer run IDs\n",
    "    print(f\"\\nğŸ—ï¸ Data Layer Run IDs:\")\n",
    "    print(f\"  Bronze: {summary_report.get('bronze_run_id')}\")\n",
    "    print(f\"  Silver: {summary_report.get('silver_run_id')}\")\n",
    "    print(f\"  Gold: {summary_report.get('gold_run_id')}\")\n",
    "    \n",
    "    # Performance summary\n",
    "    print(f\"\\nğŸ“ˆ Performance Summary:\")\n",
    "    print(f\"  Successful steps: {successful_steps}/{len(steps)}\")\n",
    "    print(f\"  Failed steps: {failed_steps}\")\n",
    "    print(f\"  No new data detected: {summary_report.get('no_new_data', False)}\")\n",
    "else:\n",
    "    print(\"âŒ Pipeline summary report not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Executive Summary - Key Insights\n",
    "\n",
    "**What happens here:**\n",
    "- Review the LLM-generated executive summary with key business insights\n",
    "- Analyze automatically calculated business metrics and KPIs\n",
    "- Understand data-driven recommendations from the Business Insights Agent\n",
    "\n",
    "**Executive Intelligence:**\n",
    "The Business Insights Agent creates high-level summaries designed for C-level executives and business decision makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze executive summary\n",
    "exec_summary_path = reports_dir / \"executive_summary.json\"\n",
    "if exec_summary_path.exists():\n",
    "    with open(exec_summary_path, 'r') as f:\n",
    "        exec_summary = json.load(f)\n",
    "    \n",
    "    print(\"ğŸ¯ EXECUTIVE SUMMARY ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"\\nğŸ“… Report Details:\")\n",
    "    print(f\"  Generated: {exec_summary.get('generated_at')}\")\n",
    "    print(f\"  Data Period: {exec_summary.get('data_period', 'N/A')}\")\n",
    "    print(f\"  Report Type: {exec_summary.get('report_type', 'Business Intelligence')}\")\n",
    "    \n",
    "    # Key business metrics\n",
    "    metrics = exec_summary.get('key_metrics', {})\n",
    "    if metrics:\n",
    "        print(f\"\\nğŸ“Š Key Business Metrics:\")\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            if isinstance(metric_value, (int, float)):\n",
    "                print(f\"  ğŸ“ˆ {metric_name}: {metric_value:,.2f}\")\n",
    "            else:\n",
    "                print(f\"  ğŸ“Š {metric_name}: {metric_value}\")\n",
    "    \n",
    "    # Strategic insights\n",
    "    insights = exec_summary.get('key_insights', [])\n",
    "    if insights:\n",
    "        print(f\"\\nğŸ’¡ Strategic Business Insights ({len(insights)}):\")\n",
    "        for i, insight in enumerate(insights, 1):\n",
    "            print(f\"  {i}. {insight}\")\n",
    "    \n",
    "    # Actionable recommendations\n",
    "    recommendations = exec_summary.get('recommendations', [])\n",
    "    if recommendations:\n",
    "        print(f\"\\nğŸ¯ Actionable Recommendations ({len(recommendations)}):\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"  {i}. {rec}\")\n",
    "    \n",
    "    # Risk assessment\n",
    "    risks = exec_summary.get('risks', [])\n",
    "    if risks:\n",
    "        print(f\"\\nâš ï¸ Business Risks Identified ({len(risks)}):\")\n",
    "        for i, risk in enumerate(risks, 1):\n",
    "            print(f\"  {i}. {risk}\")\n",
    "else:\n",
    "    print(\"âŒ Executive summary not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ C-Level Executive Report\n",
    "\n",
    "**What happens here:**\n",
    "- Review the detailed C-level executive report generated by the Business Insights Agent\n",
    "- Analyze strategic recommendations and business intelligence\n",
    "- Understand how the agent structures information for senior leadership\n",
    "\n",
    "**Executive Communication:**\n",
    "The agent creates comprehensive reports tailored for C-suite executives, focusing on strategic insights and business impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze C-level executive report\n",
    "c_level_report_path = reports_dir / \"c_level_executive_report.md\"\n",
    "if c_level_report_path.exists():\n",
    "    with open(c_level_report_path, 'r', encoding='utf-8') as f:\n",
    "        c_level_report = f.read()\n",
    "    \n",
    "    print(\"ğŸ“„ C-LEVEL EXECUTIVE REPORT ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show executive summary section\n",
    "    lines = c_level_report.split('\\n')\n",
    "    for i, line in enumerate(lines[:40]):  # First 40 lines\n",
    "        print(line)\n",
    "    \n",
    "    if len(lines) > 40:\n",
    "        print(f\"\\n... ({len(lines)-40} more lines)\")\n",
    "    \n",
    "    # Report analytics\n",
    "    print(f\"\\nğŸ“Š Report Analytics:\")\n",
    "    print(f\"  Total length: {len(c_level_report):,} characters\")\n",
    "    print(f\"  Lines: {len(lines)}\")\n",
    "    print(f\"  Sections: {c_level_report.count('#')} (estimated)\")\n",
    "    print(f\"  Key metrics mentioned: {c_level_report.lower().count('kpi') + c_level_report.lower().count('metric')}\")\n",
    "    print(f\"  Recommendations: {c_level_report.lower().count('recommend')}\")\n",
    "else:\n",
    "    print(\"âŒ C-level executive report not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘¥ Stakeholder-Specific Reports\n",
    "\n",
    "**What happens here:**\n",
    "- Analyze team-specific reports generated for different business functions\n",
    "- Review how the agent tailors insights for Marketing, Sales, Product, IT, and Customer Service teams\n",
    "- Understand role-based business intelligence delivery\n",
    "\n",
    "**Targeted Intelligence:**\n",
    "The Business Insights Agent creates customized reports that focus on metrics and insights relevant to each business function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze stakeholder-specific reports\n",
    "team_reports_dir = reports_dir / \"team_reports\"\n",
    "if team_reports_dir.exists():\n",
    "    team_report_files = list(team_reports_dir.glob(\"*.md\"))\n",
    "    \n",
    "    print(f\"ğŸ‘¥ STAKEHOLDER-SPECIFIC REPORTS ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Available Team Reports ({len(team_report_files)}):\")\n",
    "    \n",
    "    team_analysis = {}\n",
    "    \n",
    "    for report_file in team_report_files:\n",
    "        team_name = report_file.stem.replace('_team_report', '').replace('_', ' ').title()\n",
    "        \n",
    "        with open(report_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Analyze report content\n",
    "        lines = content.split('\\n')\n",
    "        word_count = len(content.split())\n",
    "        sections = content.count('#')\n",
    "        \n",
    "        team_analysis[team_name] = {\n",
    "            'lines': len(lines),\n",
    "            'words': word_count,\n",
    "            'sections': sections,\n",
    "            'content': content\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nğŸ“Š {team_name} Team Report:\")\n",
    "        print(f\"  Length: {word_count:,} words, {len(lines)} lines\")\n",
    "        print(f\"  Sections: {sections}\")\n",
    "        \n",
    "        # Show report preview\n",
    "        preview_lines = []\n",
    "        for line in lines[:12]:  # First 12 lines\n",
    "            if line.strip():\n",
    "                preview_lines.append(line)\n",
    "            if len(preview_lines) >= 6:  # Max 6 content lines\n",
    "                break\n",
    "        \n",
    "        print(f\"  Preview:\")\n",
    "        for line in preview_lines:\n",
    "            print(f\"    {line}\")\n",
    "        print(f\"    ... (truncated)\")\n",
    "    \n",
    "    # Summary of team reports\n",
    "    if team_analysis:\n",
    "        total_words = sum(t['words'] for t in team_analysis.values())\n",
    "        avg_sections = sum(t['sections'] for t in team_analysis.values()) / len(team_analysis)\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ Team Reports Summary:\")\n",
    "        print(f\"  Total reports: {len(team_analysis)}\")\n",
    "        print(f\"  Total content: {total_words:,} words\")\n",
    "        print(f\"  Average sections per report: {avg_sections:.1f}\")\n",
    "        print(f\"  Teams covered: {', '.join(team_analysis.keys())}\")\n",
    "else:\n",
    "    print(\"âŒ Team reports not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Data Visualizations and Charts\n",
    "\n",
    "**What happens here:**\n",
    "- Analyze generated charts and visualizations\n",
    "- Review dashboard components created by the Business Insights Agent\n",
    "- Understand visual business intelligence delivery\n",
    "\n",
    "**Visual Intelligence:**\n",
    "The agent creates charts and dashboards that make complex business data accessible to stakeholders through visual representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data visualizations\n",
    "charts_dir = reports_dir / \"charts\"\n",
    "if charts_dir.exists():\n",
    "    chart_files = list(charts_dir.glob(\"*.png\"))\n",
    "    \n",
    "    print(f\"ğŸ“Š DATA VISUALIZATIONS ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if chart_files:\n",
    "        print(f\"\\nğŸ“ˆ Generated Charts ({len(chart_files)}):\")\n",
    "        \n",
    "        total_size = 0\n",
    "        chart_types = {}\n",
    "        \n",
    "        for chart_file in chart_files:\n",
    "            chart_name = chart_file.stem.replace('_', ' ').title()\n",
    "            file_size = chart_file.stat().st_size\n",
    "            total_size += file_size\n",
    "            \n",
    "            # Categorize chart types\n",
    "            if 'dashboard' in chart_file.name.lower():\n",
    "                chart_type = 'Dashboard'\n",
    "            elif 'trend' in chart_file.name.lower():\n",
    "                chart_type = 'Trend Analysis'\n",
    "            elif 'performance' in chart_file.name.lower():\n",
    "                chart_type = 'Performance Metrics'\n",
    "            elif 'kpi' in chart_file.name.lower():\n",
    "                chart_type = 'KPI Visualization'\n",
    "            else:\n",
    "                chart_type = 'Business Chart'\n",
    "            \n",
    "            chart_types[chart_type] = chart_types.get(chart_type, 0) + 1\n",
    "            \n",
    "            print(f\"  ğŸ“Š {chart_name}:\")\n",
    "            print(f\"    Type: {chart_type}\")\n",
    "            print(f\"    Size: {file_size:,} bytes\")\n",
    "            print(f\"    File: {chart_file.name}\")\n",
    "        \n",
    "        # Visualization summary\n",
    "        print(f\"\\nğŸ“ˆ Visualization Summary:\")\n",
    "        print(f\"  Total charts: {len(chart_files)}\")\n",
    "        print(f\"  Total size: {total_size:,} bytes\")\n",
    "        print(f\"  Average size: {total_size/len(chart_files):,.0f} bytes\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Chart Types Distribution:\")\n",
    "        for chart_type, count in chart_types.items():\n",
    "            print(f\"  {chart_type}: {count} charts\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ Usage Instructions:\")\n",
    "        print(f\"  - Charts can be viewed in image viewers or embedded in presentations\")\n",
    "        print(f\"  - Dashboard images provide executive-level visual summaries\")\n",
    "        print(f\"  - Trend charts show business performance over time\")\n",
    "        print(f\"  - All visualizations are optimized for business reporting\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ No chart files found in {charts_dir}\")\n",
    "else:\n",
    "    print(\"âŒ Charts directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Data Quality and Pipeline Health\n",
    "\n",
    "**What happens here:**\n",
    "- Analyze data quality metrics from Gold layer data marts\n",
    "- Review pipeline performance and health indicators\n",
    "- Assess business intelligence data reliability\n",
    "\n",
    "**Quality Assurance:**\n",
    "Understanding data quality is crucial for trusting business insights and making informed decisions based on the analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data quality for business insights\n",
    "gold_data_dir = gold_dir / \"data\"\n",
    "if gold_data_dir.exists():\n",
    "    gold_files = list(gold_data_dir.glob(\"*.csv\"))\n",
    "    \n",
    "    print(f\"ğŸ” DATA QUALITY AND PIPELINE HEALTH\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if gold_files:\n",
    "        total_records = 0\n",
    "        total_columns = 0\n",
    "        data_quality_summary = {}\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Gold Layer Data Quality Assessment:\")\n",
    "        \n",
    "        for gold_file in gold_files:\n",
    "            df = pd.read_csv(gold_file)\n",
    "            records = len(df)\n",
    "            columns = len(df.columns)\n",
    "            total_records += records\n",
    "            total_columns += columns\n",
    "            \n",
    "            # Calculate data quality metrics\n",
    "            null_count = df.isnull().sum().sum()\n",
    "            total_cells = records * columns\n",
    "            null_percentage = (null_count / total_cells * 100) if total_cells > 0 else 0\n",
    "            completeness = 100 - null_percentage\n",
    "            \n",
    "            # Identify numeric columns for business metrics\n",
    "            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "            \n",
    "            data_quality_summary[gold_file.name] = {\n",
    "                'records': records,\n",
    "                'columns': columns,\n",
    "                'null_percentage': null_percentage,\n",
    "                'completeness': completeness,\n",
    "                'numeric_columns': len(numeric_cols),\n",
    "                'business_metrics_available': len(numeric_cols) > 0\n",
    "            }\n",
    "            \n",
    "            quality_icon = \"âœ…\" if completeness >= 95 else \"âš ï¸\" if completeness >= 80 else \"âŒ\"\n",
    "            print(f\"  {quality_icon} {gold_file.name}:\")\n",
    "            print(f\"    Records: {records:,}\")\n",
    "            print(f\"    Completeness: {completeness:.1f}%\")\n",
    "            print(f\"    Business metrics: {len(numeric_cols)} numeric columns\")\n",
    "        \n",
    "        # Overall quality assessment\n",
    "        avg_completeness = sum(q['completeness'] for q in data_quality_summary.values()) / len(data_quality_summary)\n",
    "        tables_with_metrics = sum(1 for q in data_quality_summary.values() if q['business_metrics_available'])\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ Overall Data Quality Summary:\")\n",
    "        print(f\"  Total business records: {total_records:,}\")\n",
    "        print(f\"  Total data marts: {len(gold_files)}\")\n",
    "        print(f\"  Average completeness: {avg_completeness:.1f}%\")\n",
    "        print(f\"  Tables with business metrics: {tables_with_metrics}/{len(gold_files)}\")\n",
    "        \n",
    "        # Quality rating\n",
    "        if avg_completeness >= 95:\n",
    "            quality_rating = \"Excellent âœ…\"\n",
    "        elif avg_completeness >= 85:\n",
    "            quality_rating = \"Good âš ï¸\"\n",
    "        elif avg_completeness >= 70:\n",
    "            quality_rating = \"Fair âš ï¸\"\n",
    "        else:\n",
    "            quality_rating = \"Poor âŒ\"\n",
    "        \n",
    "        print(f\"\\nğŸ¯ Business Intelligence Data Quality Rating: {quality_rating}\")\n",
    "        print(f\"  Recommendation: {'Data is reliable for business decisions' if avg_completeness >= 85 else 'Review data quality issues before making critical decisions'}\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ No Gold layer data found for quality assessment\")\n",
    "else:\n",
    "    print(\"âŒ Gold data not available for quality analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Business Insights Agent Execution Log\n",
    "\n",
    "**What happens here:**\n",
    "- Review the execution log of the Business Insights Agent\n",
    "- Analyze agent performance and any issues encountered\n",
    "- Understand the agent's decision-making process\n",
    "\n",
    "**Agent Monitoring:**\n",
    "Monitoring agent execution helps understand how the LLM processes business data and generates insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Business Insights Agent execution log\n",
    "business_log_path = orchestrator_dir / \"logs\" / \"business_insights.log\"\n",
    "if business_log_path.exists():\n",
    "    with open(business_log_path, 'r', encoding='utf-8') as f:\n",
    "        log_content = f.read()\n",
    "    \n",
    "    print(\"ğŸ“‹ BUSINESS INSIGHTS AGENT EXECUTION LOG\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show recent log entries\n",
    "    lines = log_content.split('\\n')\n",
    "    print(f\"\\nğŸ“„ Recent Log Entries (last 25 lines):\")\n",
    "    for line in lines[-25:] if len(lines) > 25 else lines:\n",
    "        if line.strip():\n",
    "            print(f\"  {line}\")\n",
    "    \n",
    "    # Log analysis\n",
    "    error_lines = [line for line in lines if 'ERROR' in line.upper()]\n",
    "    warning_lines = [line for line in lines if 'WARNING' in line.upper()]\n",
    "    info_lines = [line for line in lines if 'INFO' in line.upper()]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Log Analysis Summary:\")\n",
    "    print(f\"  Total log lines: {len(lines)}\")\n",
    "    print(f\"  Info messages: {len(info_lines)}\")\n",
    "    print(f\"  Warnings: {len(warning_lines)}\")\n",
    "    print(f\"  Errors: {len(error_lines)}\")\n",
    "    \n",
    "    # Show critical issues if any\n",
    "    if error_lines:\n",
    "        print(f\"\\nâŒ Critical Issues Found:\")\n",
    "        for error in error_lines[-3:]:  # Last 3 errors\n",
    "            print(f\"  {error.strip()}\")\n",
    "    \n",
    "    if warning_lines:\n",
    "        print(f\"\\nâš ï¸ Warnings Found:\")\n",
    "        for warning in warning_lines[-3:]:  # Last 3 warnings\n",
    "            print(f\"  {warning.strip()}\")\n",
    "    \n",
    "    # Agent performance indicators\n",
    "    llm_calls = log_content.lower().count('llm') + log_content.lower().count('openai')\n",
    "    report_generations = log_content.lower().count('report') + log_content.lower().count('generated')\n",
    "    \n",
    "    print(f\"\\nğŸ¤– Agent Performance Indicators:\")\n",
    "    print(f\"  LLM interactions: ~{llm_calls} (estimated)\")\n",
    "    print(f\"  Report generations: ~{report_generations} (estimated)\")\n",
    "    print(f\"  Execution status: {'âœ… Successful' if len(error_lines) == 0 else 'âŒ Issues detected'}\")\n",
    "else:\n",
    "    print(\"âŒ Business Insights Agent log not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Agent Workflow Summary\n",
    "\n",
    "**What you learned:**\n",
    "This section summarizes the entire Business Insights Agent workflow and explains how LLM agents transform data marts into actionable business intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– BUSINESS INSIGHTS AGENT WORKFLOW - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"1ï¸âƒ£ DATA ANALYSIS PHASE:\")\n",
    "print(\"   ğŸ“Š Reads Gold data marts (dimensions, facts, aggregates)\")\n",
    "print(\"   ğŸ“ˆ Analyzes pipeline summary and execution metrics\")\n",
    "print(\"   ğŸ”¢ Calculates business KPIs and performance metrics\")\n",
    "print(\"   ğŸ” Identifies trends, anomalies, and opportunities\")\n",
    "print(\"   âš¡ Performs automated data quality assessment\")\n",
    "print()\n",
    "print(\"2ï¸âƒ£ INSIGHT GENERATION PHASE:\")\n",
    "print(\"   ğŸ§  Uses LLM for data-driven insight extraction\")\n",
    "print(\"   ğŸ’¡ Generates executive summary with key findings\")\n",
    "print(\"   âš ï¸ Identifies business risks and opportunities\")\n",
    "print(\"   ğŸ¯ Creates actionable recommendations\")\n",
    "print(\"   ğŸ“Š Develops KPI interpretations and context\")\n",
    "print()\n",
    "print(\"3ï¸âƒ£ REPORT CREATION PHASE:\")\n",
    "print(\"   ğŸ‘” C-Level Executive Report (strategic insights)\")\n",
    "print(\"   ğŸ“¢ Marketing Team Report (customer & campaign insights)\")\n",
    "print(\"   ğŸ’° Sales Team Report (performance & pipeline insights)\")\n",
    "print(\"   ğŸ›ï¸ Product Management Report (product performance)\")\n",
    "print(\"   ğŸ”§ IT Operations Report (data quality & pipeline health)\")\n",
    "print(\"   ğŸ¤ Customer Service Report (customer experience insights)\")\n",
    "print()\n",
    "print(\"4ï¸âƒ£ VISUALIZATION PHASE:\")\n",
    "print(\"   ğŸ“ˆ Executive KPIs trend charts\")\n",
    "print(\"   ğŸ“Š Business performance dashboards\")\n",
    "print(\"   ğŸ” Data quality dashboards\")\n",
    "print(\"   ğŸ“‹ Custom charts based on data content\")\n",
    "print(\"   ğŸ¨ Professional visualizations for presentations\")\n",
    "print()\n",
    "print(\"âœ… RESULT: Comprehensive Business Intelligence Ecosystem\")\n",
    "print(\"   ğŸ“Š Data-driven insights for various stakeholders\")\n",
    "print(\"   ğŸ¯ Actionable recommendations for business decisions\")\n",
    "print(\"   ğŸ“ˆ Visual dashboards for executive reporting\")\n",
    "print(\"   ğŸ¤– Automated business intelligence pipeline\")\n",
    "print(\"   ğŸ“‹ Role-specific insights for different business functions\")\n",
    "print(\"   âš¡ Real-time business health monitoring\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}