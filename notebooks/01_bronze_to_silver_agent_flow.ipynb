{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bronze-to-Silver Agent Flow\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the **data cleaning process** of the Agentic ELT Pipeline.\n",
    "The Silver Layer transforms raw Bronze data into cleaned, standardized tables.\n",
    "\n",
    "### Agent Workflow:\n",
    "1. **Silver Draft Agent** â†’ Analyzes data quality and plans transformations\n",
    "2. **Silver Builder Agent** â†’ Generates executable Python code\n",
    "3. **Silver Runner** â†’ Executes cleaning and creates Silver tables\n",
    "\n",
    "### What you'll learn:\n",
    "- How LLM agents automatically detect data quality issues\n",
    "- Which transformations are applied for data cleaning\n",
    "- How agents generate code for ETL processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Setup and Configuration\n",
    "\n",
    "**What happens here:**\n",
    "- Load required Python libraries\n",
    "- Define paths to Bronze and Silver artifacts\n",
    "- Verify data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking data directories:\n",
      "Bronze Directory: ..\\artifacts\\bronze\\20260124_231016_#6470e523 (âœ… exists)\n",
      "Silver Directory: ..\\artifacts\\silver\\20260124_231016_#6470e523 (âœ… exists)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Set your Bronze and Silver Run IDs here\n",
    "# Note: Silver creates its own run_id with new timestamp but same suffix\n",
    "bronze_run_id = \"20260124_231016_#6470e523\"\n",
    "silver_run_id = \"20260124_231151_#6470e523\"  # Update this to match your Silver run\n",
    "\n",
    "# Define paths\n",
    "bronze_dir = Path(f\"../artifacts/bronze/{bronze_run_id}\")\n",
    "silver_dir = Path(f\"../artifacts/silver/{silver_run_id}\")\n",
    "\n",
    "print(f\"ğŸ” Checking data directories:\")\n",
    "print(f\"Bronze Directory: {bronze_dir} ({'âœ… exists' if bronze_dir.exists() else 'âŒ missing'})\")\n",
    "print(f\"Silver Directory: {silver_dir} ({'âœ… exists' if silver_dir.exists() else 'âŒ missing'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥‰ Bronze Layer Inspection\n",
    "\n",
    "**What happens here:**\n",
    "- Analyze raw input data from the Bronze Layer\n",
    "- Review metadata and data structures\n",
    "- Identify available tables and their properties\n",
    "\n",
    "**Why important:**\n",
    "The Silver Draft Agent needs this information to detect data quality issues and develop transformation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Bronze Layer Metadata:\n",
      "Run ID: None\n",
      "Layer: None\n",
      "\n",
      "ğŸ“ˆ Ingestion Summary:\n",
      "  Files total: 9\n",
      "  Files success: 9\n",
      "  Files failed: 0\n"
     ]
    }
   ],
   "source": [
    "# Analyze Bronze metadata\n",
    "bronze_metadata_path = bronze_dir / \"data\" / \"metadata.yaml\"\n",
    "if bronze_metadata_path.exists():\n",
    "    with open(bronze_metadata_path, 'r') as f:\n",
    "        bronze_metadata = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"ğŸ“Š Bronze Layer Metadata:\")\n",
    "    print(f\"Run ID: {bronze_metadata.get('run_id')}\")\n",
    "    print(f\"Layer: {bronze_metadata.get('layer')}\")\n",
    "    \n",
    "    summary = bronze_metadata.get('summary', {})\n",
    "    print(f\"\\nğŸ“ˆ Ingestion Summary:\")\n",
    "    print(f\"  Files total: {summary.get('files_total')}\")\n",
    "    print(f\"  Files success: {summary.get('files_success')}\")\n",
    "    print(f\"  Files failed: {summary.get('files_failed')}\")\n",
    "else:\n",
    "    print(\"âŒ Bronze metadata not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‚ï¸ Bronze Tables (9 found):\n",
      "\n",
      "ğŸ“‹ CST_AZ12.csv:\n",
      "  Dimensions: 18484 rows Ã— 3 columns\n",
      "  Columns: ['CID', 'BDATE', 'GEN']\n",
      "  Quality: 1472 NULL values, 0 duplicates\n",
      "\n",
      "ğŸ“‹ cst_info.csv:\n",
      "  Dimensions: 18494 rows Ã— 7 columns\n",
      "  Columns: ['cst_id', 'cst_key', 'cst_firstname', 'cst_lastname', 'cst_marital_status', 'cst_gndr', 'cst_create_date']\n",
      "  Quality: 4608 NULL values, 0 duplicates\n",
      "\n",
      "ğŸ“‹ customer_info.csv:\n",
      "  Dimensions: 5 rows Ã— 5 columns\n",
      "  Columns: ['customer_id', 'firstname', 'lastname', 'gender', 'date_of_birth']\n",
      "  Quality: 0 NULL values, 0 duplicates\n",
      "\n",
      "ğŸ“‹ LOC_A101.csv:\n",
      "  Dimensions: 18484 rows Ã— 2 columns\n",
      "  Columns: ['CID', 'CNTRY']\n",
      "  Quality: 332 NULL values, 0 duplicates\n",
      "\n",
      "ğŸ“‹ prd_info.csv:\n",
      "  Dimensions: 397 rows Ã— 7 columns\n",
      "  Columns: ['prd_id', 'prd_key', 'prd_nm', 'prd_cost', 'prd_line', 'prd_start_dt', 'prd_end_dt']\n",
      "  Quality: 216 NULL values, 0 duplicates\n",
      "\n",
      "ğŸ“‹ product_info.csv:\n",
      "  Dimensions: 4 rows Ã— 4 columns\n",
      "  Columns: ['product_id', 'product_name', 'category', 'price']\n",
      "  Quality: 0 NULL values, 0 duplicates\n",
      "\n",
      "ğŸ“‹ PX_CAT_G1V2.csv:\n",
      "  Dimensions: 37 rows Ã— 4 columns\n",
      "  Columns: ['ID', 'CAT', 'SUBCAT', 'MAINTENANCE']\n",
      "  Quality: 0 NULL values, 0 duplicates\n",
      "\n",
      "ğŸ“‹ sales_details.csv:\n",
      "  Dimensions: 60398 rows Ã— 9 columns\n",
      "  Columns: ['sls_ord_num', 'sls_prd_key', 'sls_cust_id', 'sls_order_dt', 'sls_ship_dt', 'sls_due_dt', 'sls_sales', 'sls_quantity', 'sls_price']\n",
      "  Quality: 15 NULL values, 0 duplicates\n",
      "\n",
      "ğŸ“‹ sales_transactions.csv:\n",
      "  Dimensions: 8 rows Ã— 6 columns\n",
      "  Columns: ['transaction_id', 'customer_id', 'product_id', 'quantity', 'unit_price', 'transaction_date']\n",
      "  Quality: 0 NULL values, 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Inspect Bronze tables\n",
    "bronze_data_dir = bronze_dir / \"data\"\n",
    "csv_files = list(bronze_data_dir.glob(\"*.csv\"))\n",
    "\n",
    "print(f\"ğŸ—‚ï¸ Bronze Tables ({len(csv_files)} found):\")\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"\\nğŸ“‹ {csv_file.name}:\")\n",
    "    print(f\"  Dimensions: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Initial data quality indicators\n",
    "    null_count = df.isnull().sum().sum()\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"  Quality: {null_count} NULL values, {duplicate_count} duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Silver Draft Agent - Data Profiling\n",
    "\n",
    "**What happens here:**\n",
    "- Simulate the automatic data profiling of the Silver Draft Agent\n",
    "- Detect data quality issues (NULL values, duplicates, formatting errors)\n",
    "- Generate transformation recommendations\n",
    "\n",
    "**Agent Logic:**\n",
    "The Silver Draft Agent analyzes each column for:\n",
    "- Data type consistency\n",
    "- Whitespace issues\n",
    "- Empty strings vs. NULL values\n",
    "- Row-level duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Silver Draft Agent Analysis:\n",
      "\n",
      "ğŸ“Š Analysis: CST_AZ12.csv\n",
      "  Quality issues: 2\n",
      "    - Whitespace in GEN\n",
      "    - 1472 NULLs in GEN\n",
      "  Transformation plan:\n",
      "    - ğŸ§¹ Trim whitespace in 'GEN'\n",
      "    - âš ï¸ Handle 1472 NULL values in 'GEN'\n",
      "\n",
      "ğŸ“Š Analysis: cst_info.csv\n",
      "  Quality issues: 8\n",
      "    - 4 NULLs in cst_id\n",
      "    - Whitespace in cst_firstname\n",
      "    - 8 NULLs in cst_firstname\n",
      "    - Whitespace in cst_lastname\n",
      "    - 7 NULLs in cst_lastname\n",
      "    - 7 NULLs in cst_marital_status\n",
      "    - 4578 NULLs in cst_gndr\n",
      "    - 4 NULLs in cst_create_date\n",
      "  Transformation plan:\n",
      "    - âš ï¸ Handle 4 NULL values in 'cst_id'\n",
      "    - ğŸ§¹ Trim whitespace in 'cst_firstname'\n",
      "    - âš ï¸ Handle 8 NULL values in 'cst_firstname'\n",
      "    - ğŸ§¹ Trim whitespace in 'cst_lastname'\n",
      "    - âš ï¸ Handle 7 NULL values in 'cst_lastname'\n",
      "    - âš ï¸ Handle 7 NULL values in 'cst_marital_status'\n",
      "    - âš ï¸ Handle 4578 NULL values in 'cst_gndr'\n",
      "    - âš ï¸ Handle 4 NULL values in 'cst_create_date'\n",
      "\n",
      "ğŸ“Š Analysis: customer_info.csv\n",
      "  Quality issues: 0\n",
      "  Transformation plan:\n",
      "    - âœ… No transformations needed\n",
      "\n",
      "ğŸ“Š Analysis: LOC_A101.csv\n",
      "  Quality issues: 2\n",
      "    - Whitespace in CNTRY\n",
      "    - 332 NULLs in CNTRY\n",
      "  Transformation plan:\n",
      "    - ğŸ§¹ Trim whitespace in 'CNTRY'\n",
      "    - âš ï¸ Handle 332 NULL values in 'CNTRY'\n",
      "\n",
      "ğŸ“Š Analysis: prd_info.csv\n",
      "  Quality issues: 4\n",
      "    - 2 NULLs in prd_cost\n",
      "    - Whitespace in prd_line\n",
      "    - 17 NULLs in prd_line\n",
      "    - 197 NULLs in prd_end_dt\n",
      "  Transformation plan:\n",
      "    - âš ï¸ Handle 2 NULL values in 'prd_cost'\n",
      "    - ğŸ§¹ Trim whitespace in 'prd_line'\n",
      "    - âš ï¸ Handle 17 NULL values in 'prd_line'\n",
      "    - âš ï¸ Handle 197 NULL values in 'prd_end_dt'\n",
      "\n",
      "ğŸ“Š Analysis: product_info.csv\n",
      "  Quality issues: 0\n",
      "  Transformation plan:\n",
      "    - âœ… No transformations needed\n",
      "\n",
      "ğŸ“Š Analysis: PX_CAT_G1V2.csv\n",
      "  Quality issues: 0\n",
      "  Transformation plan:\n",
      "    - âœ… No transformations needed\n",
      "\n",
      "ğŸ“Š Analysis: sales_details.csv\n",
      "  Quality issues: 2\n",
      "    - 8 NULLs in sls_sales\n",
      "    - 7 NULLs in sls_price\n",
      "  Transformation plan:\n",
      "    - âš ï¸ Handle 8 NULL values in 'sls_sales'\n",
      "    - âš ï¸ Handle 7 NULL values in 'sls_price'\n",
      "\n",
      "ğŸ“Š Analysis: sales_transactions.csv\n",
      "  Quality issues: 0\n",
      "  Transformation plan:\n",
      "    - âœ… No transformations needed\n"
     ]
    }
   ],
   "source": [
    "def simulate_silver_draft_agent(df, filename):\n",
    "    \"\"\"Simulates the data profiling of the Silver Draft Agent\"\"\"\n",
    "    profile = {\n",
    "        \"table\": filename,\n",
    "        \"row_count\": len(df),\n",
    "        \"column_count\": len(df.columns),\n",
    "        \"columns\": list(df.columns)\n",
    "    }\n",
    "    \n",
    "    # Agent Analysis: Identify transformation needs\n",
    "    transforms = []\n",
    "    quality_issues = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Check for whitespace issues\n",
    "        if df[col].dtype == 'object':\n",
    "            if df[col].astype(str).str.strip().ne(df[col].astype(str)).any():\n",
    "                transforms.append(f\"ğŸ§¹ Trim whitespace in '{col}'\")\n",
    "                quality_issues.append(f\"Whitespace in {col}\")\n",
    "            \n",
    "            # Check for empty strings\n",
    "            if (df[col] == \"\").any():\n",
    "                transforms.append(f\"ğŸ”„ Convert empty strings to NULL in '{col}'\")\n",
    "                quality_issues.append(f\"Empty strings in {col}\")\n",
    "        \n",
    "        # Check for NULL values\n",
    "        null_count = df[col].isnull().sum()\n",
    "        if null_count > 0:\n",
    "            transforms.append(f\"âš ï¸ Handle {null_count} NULL values in '{col}'\")\n",
    "            quality_issues.append(f\"{null_count} NULLs in {col}\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    if duplicate_count > 0:\n",
    "        transforms.append(f\"ğŸ—‘ï¸ Remove {duplicate_count} duplicate rows\")\n",
    "        quality_issues.append(f\"{duplicate_count} duplicate rows\")\n",
    "    \n",
    "    profile[\"quality_issues\"] = quality_issues\n",
    "    profile[\"suggested_transforms\"] = transforms if transforms else [\"âœ… No transformations needed\"]\n",
    "    \n",
    "    return profile\n",
    "\n",
    "# Run agent simulation for all tables\n",
    "print(\"ğŸ¤– Silver Draft Agent Analysis:\")\n",
    "table_profiles = {}\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    profile = simulate_silver_draft_agent(df, csv_file.name)\n",
    "    table_profiles[csv_file.name] = profile\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Analysis: {csv_file.name}\")\n",
    "    print(f\"  Quality issues: {len(profile['quality_issues'])}\")\n",
    "    for issue in profile['quality_issues']:\n",
    "        print(f\"    - {issue}\")\n",
    "    \n",
    "    print(f\"  Transformation plan:\")\n",
    "    for transform in profile['suggested_transforms']:\n",
    "        print(f\"    - {transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ Silver Agent Context - LLM Output\n",
    "\n",
    "**What happens here:**\n",
    "- Inspect the actual output of the Silver Draft Agent\n",
    "- Review LLM-generated analysis and recommendations\n",
    "- Compare simulated vs. real agent analysis\n",
    "\n",
    "**Agent Output:**\n",
    "The Silver Draft Agent creates structured JSON context data that the Silver Builder Agent uses to generate executable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Silver Agent Context\n",
    "silver_context_path = silver_dir / \"reports\" / \"silver_run_agent_context.json\"\n",
    "if silver_context_path.exists():\n",
    "    with open(silver_context_path, 'r') as f:\n",
    "        silver_context = json.load(f)\n",
    "    \n",
    "    print(\"ğŸ¤– Silver Draft Agent - LLM Output:\")\n",
    "    print(f\"Run ID: {silver_context.get('run_id')}\")\n",
    "    print(f\"Layer: {silver_context.get('layer')}\")\n",
    "    print(f\"Source Layer: {silver_context.get('source_layer')}\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    perf = silver_context.get('performance_metrics', {})\n",
    "    print(f\"\\nğŸ“ˆ Agent Performance:\")\n",
    "    print(f\"  Rows processed: {perf.get('total_rows_processed', 0):,}\")\n",
    "    print(f\"  Columns processed: {perf.get('total_columns_processed', 0):,}\")\n",
    "    print(f\"  Tables processed: {perf.get('tables_processed', 0)}\")\n",
    "    print(f\"  Tables failed: {perf.get('tables_failed', 0)}\")\n",
    "    \n",
    "    # Schema overview from agent\n",
    "    if 'profile' in silver_context:\n",
    "        print(f\"\\nğŸ” Agent Schema Analysis:\")\n",
    "        schema = silver_context['profile'].get('schema_overview', {})\n",
    "        for table in schema.get('tables', []):\n",
    "            print(f\"  ğŸ“‹ {table['table']}: {table['row_count']} rows, {table['column_count']} columns\")\n",
    "else:\n",
    "    print(\"âŒ Silver Agent Context not found - Agent was not executed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Silver Human Report - LLM Insights\n",
    "\n",
    "**What happens here:**\n",
    "- Display the human-readable report from the Silver Draft Agent\n",
    "- Review LLM-generated data quality analysis\n",
    "- Understand agent recommendations for business stakeholders\n",
    "\n",
    "**Report Content:**\n",
    "The agent creates a structured Markdown report with executive summary, data quality assessment, and transformation recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Silver Human Report\n",
    "silver_report_path = silver_dir / \"reports\" / \"silver_run_human_report.md\"\n",
    "if silver_report_path.exists():\n",
    "    with open(silver_report_path, 'r', encoding='utf-8') as f:\n",
    "        silver_report = f.read()\n",
    "    \n",
    "    print(\"ğŸ“„ Silver Draft Agent - Human Report:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show first part of report\n",
    "    lines = silver_report.split('\\n')\n",
    "    for i, line in enumerate(lines[:30]):  # First 30 lines\n",
    "        print(line)\n",
    "    \n",
    "    if len(lines) > 30:\n",
    "        print(f\"\\n... ({len(lines)-30} more lines)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Report Statistics:\")\n",
    "    print(f\"  Total length: {len(silver_report):,} characters\")\n",
    "    print(f\"  Lines: {len(lines)}\")\n",
    "    print(f\"  Sections: {silver_report.count('#')} (estimated)\")\n",
    "else:\n",
    "    print(\"âŒ Silver Human Report not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥ˆ Silver Layer Results\n",
    "\n",
    "**What happens here:**\n",
    "- Inspect the transformed Silver data\n",
    "- Compare Bronze vs. Silver versions of tables\n",
    "- Verify data quality improvements\n",
    "\n",
    "**Transformation Results:**\n",
    "The Silver Runner has executed the transformations generated by the Silver Builder Agent and created cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Silver transformation results\n",
    "silver_data_dir = silver_dir / \"data\"\n",
    "if silver_data_dir.exists():\n",
    "    silver_csv_files = list(silver_data_dir.glob(\"*.csv\"))\n",
    "    \n",
    "    print(f\"ğŸ¥ˆ Silver Layer Results ({len(silver_csv_files)} tables):\")\n",
    "    \n",
    "    for csv_file in silver_csv_files:\n",
    "        df_silver = pd.read_csv(csv_file)\n",
    "        print(f\"\\nğŸ“Š {csv_file.name}:\")\n",
    "        print(f\"  Silver: {df_silver.shape[0]} rows Ã— {df_silver.shape[1]} columns\")\n",
    "        \n",
    "        # Compare with Bronze version\n",
    "        bronze_equivalent = bronze_data_dir / csv_file.name\n",
    "        if bronze_equivalent.exists():\n",
    "            df_bronze = pd.read_csv(bronze_equivalent)\n",
    "            \n",
    "            # Data quality improvements\n",
    "            bronze_nulls = df_bronze.isnull().sum().sum()\n",
    "            silver_nulls = df_silver.isnull().sum().sum()\n",
    "            bronze_dupes = df_bronze.duplicated().sum()\n",
    "            silver_dupes = df_silver.duplicated().sum()\n",
    "            \n",
    "            print(f\"  ğŸ“ˆ Quality improvements:\")\n",
    "            print(f\"    Rows: {df_bronze.shape[0]} â†’ {df_silver.shape[0]} ({df_silver.shape[0] - df_bronze.shape[0]:+d})\")\n",
    "            print(f\"    NULL values: {bronze_nulls} â†’ {silver_nulls} ({silver_nulls - bronze_nulls:+d})\")\n",
    "            print(f\"    Duplicates: {bronze_dupes} â†’ {silver_dupes} ({silver_dupes - bronze_dupes:+d})\")\n",
    "            \n",
    "            # Data type improvements\n",
    "            print(f\"  ğŸ”„ Data type transformations:\")\n",
    "            for col in df_silver.columns:\n",
    "                if col in df_bronze.columns:\n",
    "                    bronze_type = str(df_bronze[col].dtype)\n",
    "                    silver_type = str(df_silver[col].dtype)\n",
    "                    if bronze_type != silver_type:\n",
    "                        print(f\"    {col}: {bronze_type} â†’ {silver_type}\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ No Bronze comparison data found\")\n",
    "else:\n",
    "    print(\"âŒ Silver data not found - Transformation not executed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Data Quality Dashboard\n",
    "\n",
    "**What happens here:**\n",
    "- Create overview of data quality improvements\n",
    "- Quantify agent performance\n",
    "- Assess transformation success\n",
    "\n",
    "**Quality Metrics:**\n",
    "Compare data quality before and after Silver transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data quality dashboard\n",
    "if silver_data_dir.exists() and bronze_data_dir.exists():\n",
    "    print(\"ğŸ“Š DATA QUALITY DASHBOARD\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_bronze_rows = 0\n",
    "    total_silver_rows = 0\n",
    "    total_bronze_nulls = 0\n",
    "    total_silver_nulls = 0\n",
    "    total_bronze_dupes = 0\n",
    "    total_silver_dupes = 0\n",
    "    tables_processed = 0\n",
    "    \n",
    "    for csv_file in silver_csv_files:\n",
    "        bronze_file = bronze_data_dir / csv_file.name\n",
    "        if bronze_file.exists():\n",
    "            df_bronze = pd.read_csv(bronze_file)\n",
    "            df_silver = pd.read_csv(csv_file)\n",
    "            \n",
    "            total_bronze_rows += len(df_bronze)\n",
    "            total_silver_rows += len(df_silver)\n",
    "            total_bronze_nulls += df_bronze.isnull().sum().sum()\n",
    "            total_silver_nulls += df_silver.isnull().sum().sum()\n",
    "            total_bronze_dupes += df_bronze.duplicated().sum()\n",
    "            total_silver_dupes += df_silver.duplicated().sum()\n",
    "            tables_processed += 1\n",
    "    \n",
    "    print(f\"ğŸ“ˆ OVERALL STATISTICS:\")\n",
    "    print(f\"  Tables processed: {tables_processed}\")\n",
    "    print(f\"  Rows: {total_bronze_rows:,} â†’ {total_silver_rows:,} ({total_silver_rows - total_bronze_rows:+,})\")\n",
    "    print(f\"  NULL values: {total_bronze_nulls:,} â†’ {total_silver_nulls:,} ({total_silver_nulls - total_bronze_nulls:+,})\")\n",
    "    print(f\"  Duplicates: {total_bronze_dupes:,} â†’ {total_silver_dupes:,} ({total_silver_dupes - total_bronze_dupes:+,})\")\n",
    "    \n",
    "    # Calculate quality score\n",
    "    if total_bronze_rows > 0:\n",
    "        bronze_quality = (1 - (total_bronze_nulls + total_bronze_dupes) / (total_bronze_rows * 10)) * 100\n",
    "        silver_quality = (1 - (total_silver_nulls + total_silver_dupes) / (total_silver_rows * 10)) * 100\n",
    "        quality_improvement = silver_quality - bronze_quality\n",
    "        \n",
    "        print(f\"\\nğŸ¯ QUALITY SCORE:\")\n",
    "        print(f\"  Bronze Layer: {bronze_quality:.1f}%\")\n",
    "        print(f\"  Silver Layer: {silver_quality:.1f}%\")\n",
    "        print(f\"  Improvement: {quality_improvement:+.1f}%\")\n",
    "else:\n",
    "    print(\"âŒ Cannot create data quality dashboard - Data missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Agent Workflow Summary\n",
    "\n",
    "**What you learned:**\n",
    "This section summarizes the entire Silver Agent workflow and explains the role of each agent in the data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– SILVER AGENT WORKFLOW - SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"1ï¸âƒ£ SILVER DRAFT AGENT (Analysis & Planning):\")\n",
    "print(\"   ğŸ” Reads Bronze metadata and CSV files\")\n",
    "print(\"   ğŸ“Š Performs automatic data profiling\")\n",
    "print(\"   âš ï¸ Identifies data quality issues\")\n",
    "print(\"   ğŸ’¡ Suggests specific transformations\")\n",
    "print(\"   ğŸ“„ Creates silver_run_agent_context.json\")\n",
    "print(\"   ğŸ“ Creates silver_run_human_report.md\")\n",
    "print()\n",
    "print(\"2ï¸âƒ£ SILVER BUILDER AGENT (Code Generation):\")\n",
    "print(\"   ğŸ“– Reads Silver Draft Context\")\n",
    "print(\"   ğŸ› ï¸ Generates executable Python code\")\n",
    "print(\"   ğŸ”§ Implements suggested transformations\")\n",
    "print(\"   ğŸ“œ Creates load_2_silver_layer_runner.py\")\n",
    "print()\n",
    "print(\"3ï¸âƒ£ SILVER RUNNER (Execution):\")\n",
    "print(\"   â–¶ï¸ Executes generated code\")\n",
    "print(\"   ğŸ”„ Transforms Bronze â†’ Silver\")\n",
    "print(\"   ğŸ’¾ Creates cleaned CSV files\")\n",
    "print(\"   ğŸ“‹ Generates metadata and reports\")\n",
    "print()\n",
    "print(\"âœ… RESULT: Cleaned, standardized Silver-Layer data\")\n",
    "print(\"   - Consistent data types\")\n",
    "print(\"   - Removed duplicates\")\n",
    "print(\"   - Standardized NULL values\")\n",
    "print(\"   - Clean formatting\")\n",
    "print(\"   - Complete documentation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
