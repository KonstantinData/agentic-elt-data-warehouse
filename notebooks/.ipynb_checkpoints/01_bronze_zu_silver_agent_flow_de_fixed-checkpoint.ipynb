{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bronze-zu-Silver Agent Flow\n",
    "\n",
    "## Ãœberblick\n",
    "Dieses Notebook demonstriert den **Datenbereinigungsprozess** der Agentic ELT Pipeline.\n",
    "Der Silver Layer transformiert rohe Bronze-Daten in bereinigte, standardisierte Tabellen.\n",
    "\n",
    "### Agent-Workflow:\n",
    "1. **Silver Draft Agent** â†’ Analysiert DatenqualitÃ¤t und plant Transformationen\n",
    "2. **Silver Builder Agent** â†’ Generiert ausfÃ¼hrbaren Python-Code\n",
    "3. **Silver Runner** â†’ FÃ¼hrt Bereinigung aus und erstellt Silver-Tabellen\n",
    "\n",
    "### Was Sie lernen:\n",
    "- Wie LLM-Agents DatenqualitÃ¤tsprobleme automatisch erkennen\n",
    "- Welche Transformationen fÃ¼r Datenbereinigung angewendet werden\n",
    "- Wie Agents Code fÃ¼r ETL-Prozesse generieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Setup und Konfiguration\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Laden der benÃ¶tigten Python-Bibliotheken\n",
    "- Definition der Pfade zu Bronze- und Silver-Artefakten\n",
    "- ÃœberprÃ¼fung der DatenverfÃ¼gbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ÃœberprÃ¼fe Datenverzeichnisse:\n",
      "Bronze Directory: ..\\artifacts\\bronze\\20260124_231016_#6470e523 (âœ… vorhanden)\n",
      "Silver Directory: ..\\artifacts\\silver\\20260124_231016_#6470e523 (âœ… vorhanden)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Setzen Sie hier Ihre Run-ID\n",
    "run_id = \"20260124_231016_#6470e523\"\n",
    "\n",
    "# Pfade definieren\n",
    "bronze_dir = Path(f\"../artifacts/bronze/{run_id}\")\n",
    "silver_dir = Path(f\"../artifacts/silver/{run_id}\")\n",
    "\n",
    "print(f\"ğŸ” ÃœberprÃ¼fe Datenverzeichnisse:\")\n",
    "print(f\"Bronze Directory: {bronze_dir} ({'âœ… vorhanden' if bronze_dir.exists() else 'âŒ fehlt'})\")\n",
    "print(f\"Silver Directory: {silver_dir} ({'âœ… vorhanden' if silver_dir.exists() else 'âŒ fehlt'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥‰ Bronze Layer Inspektion\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Analyse der rohen Eingangsdaten aus dem Bronze Layer\n",
    "- ÃœberprÃ¼fung der Metadaten und Datenstrukturen\n",
    "- Identifikation der verfÃ¼gbaren Tabellen und deren Eigenschaften\n",
    "\n",
    "**Warum wichtig:**\n",
    "Der Silver Draft Agent benÃ¶tigt diese Informationen, um DatenqualitÃ¤tsprobleme zu erkennen und Transformationsstrategien zu entwickeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Bronze Layer Metadata:\n",
      "Run ID: None\n",
      "Layer: None\n",
      "\n",
      "ğŸ“ˆ Ingestion Zusammenfassung:\n",
      "  Dateien gesamt: 9\n",
      "  Dateien erfolgreich: 9\n",
      "  Dateien fehlgeschlagen: 0\n"
     ]
    }
   ],
   "source": [
    "# Bronze Metadata analysieren (robust + validiert)\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "def _load_yaml(path: Path) -> dict:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Metadata nicht gefunden: {path.resolve()}\")\n",
    "    data = yaml.safe_load(path.read_text(encoding=\"utf-8\")) or {}\n",
    "    if not isinstance(data, dict):\n",
    "        raise TypeError(f\"Unerwartetes YAML-Format (kein Mapping) in {path.resolve()}: {type(data)}\")\n",
    "    return data\n",
    "\n",
    "def _require(meta: dict, *keys: str, path: Path = None):\n",
    "    cur = meta\n",
    "    for k in keys:\n",
    "        if not isinstance(cur, dict) or k not in cur:\n",
    "            available = list(cur.keys()) if isinstance(cur, dict) else None\n",
    "            where = f\" in {path.resolve()}\" if path else \"\"\n",
    "            raise KeyError(\n",
    "                f\"Fehlender Key: {'/'.join(keys)}{where}. \"\n",
    "                f\"VerfÃ¼gbare Keys auf dieser Ebene: {available}\"\n",
    "            )\n",
    "        cur = cur[k]\n",
    "    return cur\n",
    "\n",
    "bronze_metadata_path = bronze_dir / \"data\" / \"metadata.yaml\"\n",
    "bronze_metadata = None\n",
    "\n",
    "try:\n",
    "    bronze_metadata = _load_yaml(bronze_metadata_path)\n",
    "\n",
    "    # Pflichtfelder (frÃ¼h & laut scheitern, falls Schema nicht passt)\n",
    "    run_id_val = _require(bronze_metadata, \"run\", \"run_id\", path=bronze_metadata_path)\n",
    "    layer_val  = _require(bronze_metadata, \"run\", \"layer\",  path=bronze_metadata_path)\n",
    "\n",
    "    print(\"ğŸ“Š Bronze Layer Metadata:\")\n",
    "    print(f\"Run ID: {run_id_val}\")\n",
    "    print(f\"Layer: {layer_val}\")\n",
    "\n",
    "    # Optionale Felder\n",
    "    summary = bronze_metadata.get(\"summary\", {}) or {}\n",
    "    print(f\"\\nğŸ“ˆ Ingestion Zusammenfassung:\")\n",
    "    print(f\"  Dateien gesamt: {summary.get('files_total')}\")\n",
    "    print(f\"  Dateien erfolgreich: {summary.get('files_success')}\")\n",
    "    print(f\"  Dateien fehlgeschlagen: {summary.get('files_failed')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"âŒ Fehler beim Laden/Validieren der Bronze-Metadata:\")\n",
    "    print(f\"  {e}\")\n",
    "    print(\"\\nğŸ” Debug:\")\n",
    "    print(f\"  Pfad: {bronze_metadata_path}\")\n",
    "    print(f\"  Absolut: {bronze_metadata_path.resolve()}\")\n",
    "    print(f\"  Existiert: {bronze_metadata_path.exists()}\")\n",
    "\n",
    "    if isinstance(bronze_metadata, dict):\n",
    "        print(f\"  Top-Level Keys: {list(bronze_metadata.keys())}\")\n",
    "        run_block = bronze_metadata.get(\"run\")\n",
    "        if isinstance(run_block, dict):\n",
    "            print(f\"  run Keys: {list(run_block.keys())}\")\n",
    "        else:\n",
    "            print(f\"  run Typ: {type(run_block)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bronze Tabellen inspizieren\n",
    "bronze_data_dir = bronze_dir / \"data\"\n",
    "csv_files = list(bronze_data_dir.glob(\"*.csv\"))\n",
    "\n",
    "print(f\"ğŸ—‚ï¸ Bronze Tabellen ({len(csv_files)} gefunden):\")\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"\\nğŸ“‹ {csv_file.name}:\")\n",
    "    print(f\"  Dimensionen: {df.shape[0]} Zeilen Ã— {df.shape[1]} Spalten\")\n",
    "    print(f\"  Spalten: {list(df.columns)}\")\n",
    "\n",
    "    # Erste DatenqualitÃ¤tsindikatoren\n",
    "    null_count = df.isnull().sum().sum()\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"  QualitÃ¤t: {null_count} NULL-Werte, {duplicate_count} Duplikate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ğŸ¤– Silver Draft Agent - Datenprofilierung\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Simulation der automatischen Datenprofilierung des Silver Draft Agents\n",
    "- Erkennung von DatenqualitÃ¤tsproblemen (NULL-Werte, Duplikate, Formatierungsfehler)\n",
    "- Generierung von Transformationsempfehlungen\n",
    "\n",
    "**Agent-Logik:**\n",
    "Der Silver Draft Agent analysiert jede Spalte auf:\n",
    "- Datentyp-Konsistenz\n",
    "- Whitespace-Probleme\n",
    "- Leere Strings vs. NULL-Werte\n",
    "- Duplikate auf Zeilenebene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_silver_draft_agent(df, filename):\n",
    "    \"\"\"Simuliert die Datenprofilierung des Silver Draft Agents\"\"\"\n",
    "    profile = {\n",
    "        \"table\": filename,\n",
    "        \"row_count\": len(df),\n",
    "        \"column_count\": len(df.columns),\n",
    "        \"columns\": list(df.columns)\n",
    "    }\n",
    "\n",
    "    # Agent-Analyse: Identifiziere Transformationsbedarfe\n",
    "    transforms = []\n",
    "    quality_issues = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        # PrÃ¼fe auf Whitespace-Probleme\n",
    "        if df[col].dtype == 'object':\n",
    "            if df[col].astype(str).str.strip().ne(df[col].astype(str)).any():\n",
    "                transforms.append(f\"ğŸ§¹ Whitespace entfernen in '{col}'\")\n",
    "                quality_issues.append(f\"Whitespace in {col}\")\n",
    "\n",
    "            # PrÃ¼fe auf leere Strings\n",
    "            if (df[col] == \"\").any():\n",
    "                transforms.append(f\"ğŸ”„ Leere Strings zu NULL konvertieren in '{col}'\")\n",
    "                quality_issues.append(f\"Leere Strings in {col}\")\n",
    "\n",
    "        # PrÃ¼fe auf NULL-Werte\n",
    "        null_count = df[col].isnull().sum()\n",
    "        if null_count > 0:\n",
    "            transforms.append(f\"âš ï¸ {null_count} NULL-Werte behandeln in '{col}'\")\n",
    "            quality_issues.append(f\"{null_count} NULLs in {col}\")\n",
    "\n",
    "    # PrÃ¼fe auf Duplikate\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    if duplicate_count > 0:\n",
    "        transforms.append(f\"ğŸ—‘ï¸ {duplicate_count} doppelte Zeilen entfernen\")\n",
    "        quality_issues.append(f\"{duplicate_count} doppelte Zeilen\")\n",
    "\n",
    "    profile[\"quality_issues\"] = quality_issues\n",
    "    profile[\"suggested_transforms\"] = transforms if transforms else [\"âœ… Keine Transformationen erforderlich\"]\n",
    "\n",
    "    return profile\n",
    "\n",
    "# FÃ¼hre Agent-Simulation fÃ¼r alle Tabellen aus\n",
    "print(\"ğŸ¤– Silver Draft Agent Analyse:\")\n",
    "table_profiles = {}\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    profile = simulate_silver_draft_agent(df, csv_file.name)\n",
    "    table_profiles[csv_file.name] = profile\n",
    "\n",
    "    print(f\"\\nğŸ“Š Analyse: {csv_file.name}\")\n",
    "    print(f\"  QualitÃ¤tsprobleme: {len(profile['quality_issues'])}\")\n",
    "    for issue in profile['quality_issues']:\n",
    "        print(f\"    - {issue}\")\n",
    "\n",
    "    print(f\"  Transformationsplan:\")\n",
    "    for transform in profile['suggested_transforms']:\n",
    "        print(f\"    - {transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ Silver Agent Context - LLM Output\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Inspektion des tatsÃ¤chlichen Outputs des Silver Draft Agents\n",
    "- ÃœberprÃ¼fung der vom LLM generierten Analyse und Empfehlungen\n",
    "- Vergleich zwischen simulierter und echter Agent-Analyse\n",
    "\n",
    "**Agent-Output:**\n",
    "Der Silver Draft Agent erstellt strukturierte JSON-Kontextdaten, die der Silver Builder Agent verwendet, um ausfÃ¼hrbaren Code zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silver Agent Context analysieren\n",
    "silver_context_path = silver_dir / \"reports\" / \"silver_run_agent_context.json\"\n",
    "if silver_context_path.exists():\n",
    "    with open(silver_context_path, 'r') as f:\n",
    "        silver_context = json.load(f)\n",
    "\n",
    "    print(\"ğŸ¤– Silver Draft Agent - LLM Output:\")\n",
    "    print(f\"Run ID: {silver_context.get('run_id')}\")\n",
    "    print(f\"Layer: {silver_context.get('layer')}\")\n",
    "    print(f\"Quell-Layer: {silver_context.get('source_layer')}\")\n",
    "\n",
    "    # Performance Metriken\n",
    "    perf = silver_context.get('performance_metrics', {})\n",
    "    print(f\"\\nğŸ“ˆ Agent Performance:\")\n",
    "    print(f\"  Zeilen verarbeitet: {perf.get('total_rows_processed', 0):,}\")\n",
    "    print(f\"  Spalten verarbeitet: {perf.get('total_columns_processed', 0):,}\")\n",
    "    print(f\"  Tabellen verarbeitet: {perf.get('tables_processed', 0)}\")\n",
    "    print(f\"  Tabellen fehlgeschlagen: {perf.get('tables_failed', 0)}\")\n",
    "\n",
    "    # Schema-Ãœbersicht vom Agent\n",
    "    if 'profile' in silver_context:\n",
    "        print(f\"\\nğŸ” Agent Schema-Analyse:\")\n",
    "        schema = silver_context['profile'].get('schema_overview', {})\n",
    "        for table in schema.get('tables', []):\n",
    "            print(f\"  ğŸ“‹ {table['table']}: {table['row_count']} Zeilen, {table['column_count']} Spalten\")\n",
    "else:\n",
    "    print(\"âŒ Silver Agent Context nicht gefunden - Agent wurde nicht ausgefÃ¼hrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Silver Human Report - LLM Insights\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Anzeige des menschenlesbaren Reports des Silver Draft Agents\n",
    "- ÃœberprÃ¼fung der LLM-generierten DatenqualitÃ¤tsanalyse\n",
    "- Einsicht in die Agent-Empfehlungen fÃ¼r Business-Stakeholder\n",
    "\n",
    "**Report-Inhalt:**\n",
    "Der Agent erstellt einen strukturierten Markdown-Report mit Executive Summary, DatenqualitÃ¤tsbewertung und Transformationsempfehlungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silver Human Report inspizieren\n",
    "silver_report_path = silver_dir / \"reports\" / \"silver_run_human_report.md\"\n",
    "if silver_report_path.exists():\n",
    "    with open(silver_report_path, 'r', encoding='utf-8') as f:\n",
    "        silver_report = f.read()\n",
    "\n",
    "    print(\"ğŸ“„ Silver Draft Agent - Human Report:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Zeige ersten Teil des Reports\n",
    "    lines = silver_report.split('\\n')\n",
    "    for i, line in enumerate(lines[:30]):  # Erste 30 Zeilen\n",
    "        print(line)\n",
    "\n",
    "    if len(lines) > 30:\n",
    "        print(f\"\\n... ({len(lines)-30} weitere Zeilen)\")\n",
    "\n",
    "    print(f\"\\nğŸ“Š Report Statistiken:\")\n",
    "    print(f\"  GesamtlÃ¤nge: {len(silver_report):,} Zeichen\")\n",
    "    print(f\"  Zeilen: {len(lines)}\")\n",
    "    print(f\"  Abschnitte: {silver_report.count('#')} (geschÃ¤tzt)\")\n",
    "else:\n",
    "    print(\"âŒ Silver Human Report nicht gefunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥ˆ Silver Layer Ergebnisse\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Inspektion der transformierten Silver-Daten\n",
    "- Vergleich zwischen Bronze- und Silver-Versionen der Tabellen\n",
    "- ÃœberprÃ¼fung der DatenqualitÃ¤tsverbesserungen\n",
    "\n",
    "**Transformationsergebnisse:**\n",
    "Der Silver Runner hat die vom Silver Builder Agent generierten Transformationen ausgefÃ¼hrt und bereinigte Daten erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silver Transformationsergebnisse analysieren\n",
    "silver_data_dir = silver_dir / \"data\"\n",
    "if silver_data_dir.exists():\n",
    "    silver_csv_files = list(silver_data_dir.glob(\"*.csv\"))\n",
    "\n",
    "    print(f\"ğŸ¥ˆ Silver Layer Ergebnisse ({len(silver_csv_files)} Tabellen):\")\n",
    "\n",
    "    for csv_file in silver_csv_files:\n",
    "        df_silver = pd.read_csv(csv_file)\n",
    "        print(f\"\\nğŸ“Š {csv_file.name}:\")\n",
    "        print(f\"  Silver: {df_silver.shape[0]} Zeilen Ã— {df_silver.shape[1]} Spalten\")\n",
    "\n",
    "        # Vergleiche mit Bronze-Version\n",
    "        bronze_equivalent = bronze_data_dir / csv_file.name\n",
    "        if bronze_equivalent.exists():\n",
    "            df_bronze = pd.read_csv(bronze_equivalent)\n",
    "\n",
    "            # DatenqualitÃ¤tsverbesserungen\n",
    "            bronze_nulls = df_bronze.isnull().sum().sum()\n",
    "            silver_nulls = df_silver.isnull().sum().sum()\n",
    "            bronze_dupes = df_bronze.duplicated().sum()\n",
    "            silver_dupes = df_silver.duplicated().sum()\n",
    "\n",
    "            print(f\"  ğŸ“ˆ QualitÃ¤tsverbesserungen:\")\n",
    "            print(f\"    Zeilen: {df_bronze.shape[0]} â†’ {df_silver.shape[0]} ({df_silver.shape[0] - df_bronze.shape[0]:+d})\")\n",
    "            print(f\"    NULL-Werte: {bronze_nulls} â†’ {silver_nulls} ({silver_nulls - bronze_nulls:+d})\")\n",
    "            print(f\"    Duplikate: {bronze_dupes} â†’ {silver_dupes} ({silver_dupes - bronze_dupes:+d})\")\n",
    "\n",
    "            # Datentyp-Verbesserungen\n",
    "            print(f\"  ğŸ”„ Datentyp-Transformationen:\")\n",
    "            for col in df_silver.columns:\n",
    "                if col in df_bronze.columns:\n",
    "                    bronze_type = str(df_bronze[col].dtype)\n",
    "                    silver_type = str(df_silver[col].dtype)\n",
    "                    if bronze_type != silver_type:\n",
    "                        print(f\"    {col}: {bronze_type} â†’ {silver_type}\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ Keine Bronze-Vergleichsdaten gefunden\")\n",
    "else:\n",
    "    print(\"âŒ Silver Daten nicht gefunden - Transformation nicht ausgefÃ¼hrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š DatenqualitÃ¤ts-Dashboard\n",
    "\n",
    "**Was passiert hier:**\n",
    "- Erstellung einer Ãœbersicht Ã¼ber die DatenqualitÃ¤tsverbesserungen\n",
    "- Quantifizierung der Agent-Performance\n",
    "- Bewertung der Transformationserfolge\n",
    "\n",
    "**QualitÃ¤tsmetriken:**\n",
    "Vergleich der DatenqualitÃ¤t vor und nach der Silver-Transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatenqualitÃ¤ts-Dashboard erstellen\n",
    "if silver_data_dir.exists() and bronze_data_dir.exists():\n",
    "    print(\"ğŸ“Š DATENQUALITÃ„TS-DASHBOARD\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    total_bronze_rows = 0\n",
    "    total_silver_rows = 0\n",
    "    total_bronze_nulls = 0\n",
    "    total_silver_nulls = 0\n",
    "    total_bronze_dupes = 0\n",
    "    total_silver_dupes = 0\n",
    "    tables_processed = 0\n",
    "\n",
    "    for csv_file in silver_csv_files:\n",
    "        bronze_file = bronze_data_dir / csv_file.name\n",
    "        if bronze_file.exists():\n",
    "            df_bronze = pd.read_csv(bronze_file)\n",
    "            df_silver = pd.read_csv(csv_file)\n",
    "\n",
    "            total_bronze_rows += len(df_bronze)\n",
    "            total_silver_rows += len(df_silver)\n",
    "            total_bronze_nulls += df_bronze.isnull().sum().sum()\n",
    "            total_silver_nulls += df_silver.isnull().sum().sum()\n",
    "            total_bronze_dupes += df_bronze.duplicated().sum()\n",
    "            total_silver_dupes += df_silver.duplicated().sum()\n",
    "            tables_processed += 1\n",
    "\n",
    "    print(f\"ğŸ“ˆ GESAMTSTATISTIKEN:\")\n",
    "    print(f\"  Tabellen verarbeitet: {tables_processed}\")\n",
    "    print(f\"  Zeilen: {total_bronze_rows:,} â†’ {total_silver_rows:,} ({total_silver_rows - total_bronze_rows:+,})\")\n",
    "    print(f\"  NULL-Werte: {total_bronze_nulls:,} â†’ {total_silver_nulls:,} ({total_silver_nulls - total_bronze_nulls:+,})\")\n",
    "    print(f\"  Duplikate: {total_bronze_dupes:,} â†’ {total_silver_dupes:,} ({total_silver_dupes - total_bronze_dupes:+,})\")\n",
    "\n",
    "    # QualitÃ¤tsscore berechnen\n",
    "    if total_bronze_rows > 0:\n",
    "        bronze_quality = (1 - (total_bronze_nulls + total_bronze_dupes) / (total_bronze_rows * 10)) * 100\n",
    "        silver_quality = (1 - (total_silver_nulls + total_silver_dupes) / (total_silver_rows * 10)) * 100\n",
    "        quality_improvement = silver_quality - bronze_quality\n",
    "\n",
    "        print(f\"\\nğŸ¯ QUALITÃ„TSSCORE:\")\n",
    "        print(f\"  Bronze Layer: {bronze_quality:.1f}%\")\n",
    "        print(f\"  Silver Layer: {silver_quality:.1f}%\")\n",
    "        print(f\"  Verbesserung: {quality_improvement:+.1f}%\")\n",
    "else:\n",
    "    print(\"âŒ Kann DatenqualitÃ¤ts-Dashboard nicht erstellen - Daten fehlen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Agent-Workflow Zusammenfassung\n",
    "\n",
    "**Was Sie gelernt haben:**\n",
    "Dieser Abschnitt fasst den gesamten Silver Agent Workflow zusammen und erklÃ¤rt die Rolle jedes Agents im Datenbereinigungsprozess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– SILVER AGENT WORKFLOW - ZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"1ï¸âƒ£ SILVER DRAFT AGENT (Analyse & Planung):\")\n",
    "print(\"   ğŸ” Liest Bronze-Metadaten und CSV-Dateien\")\n",
    "print(\"   ğŸ“Š FÃ¼hrt automatische Datenprofilierung durch\")\n",
    "print(\"   âš ï¸ Identifiziert DatenqualitÃ¤tsprobleme\")\n",
    "print(\"   ğŸ’¡ SchlÃ¤gt spezifische Transformationen vor\")\n",
    "print(\"   ğŸ“„ Erstellt silver_run_agent_context.json\")\n",
    "print(\"   ğŸ“ Erstellt silver_run_human_report.md\")\n",
    "print()\n",
    "print(\"2ï¸âƒ£ SILVER BUILDER AGENT (Code-Generierung):\")\n",
    "print(\"   ğŸ“– Liest Silver Draft Context\")\n",
    "print(\"   ğŸ› ï¸ Generiert ausfÃ¼hrbaren Python-Code\")\n",
    "print(\"   ğŸ”§ Implementiert vorgeschlagene Transformationen\")\n",
    "print(\"   ğŸ“œ Erstellt load_2_silver_layer_runner.py\")\n",
    "print()\n",
    "print(\"3ï¸âƒ£ SILVER RUNNER (AusfÃ¼hrung):\")\n",
    "print(\"   â–¶ï¸ FÃ¼hrt generierten Code aus\")\n",
    "print(\"   ğŸ”„ Transformiert Bronze â†’ Silver\")\n",
    "print(\"   ğŸ’¾ Erstellt bereinigte CSV-Dateien\")\n",
    "print(\"   ğŸ“‹ Generiert Metadaten und Reports\")\n",
    "print()\n",
    "print(\"âœ… ERGEBNIS: Bereinigte, standardisierte Silver-Layer Daten\")\n",
    "print(\"   - Konsistente Datentypen\")\n",
    "print(\"   - Entfernte Duplikate\")\n",
    "print(\"   - Standardisierte NULL-Werte\")\n",
    "print(\"   - Bereinigte Formatierung\")\n",
    "print(\"   - VollstÃ¤ndige Dokumentation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
